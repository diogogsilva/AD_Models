{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"best_model_cnn.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN4maYn7td7hoNMn7Pr+N9W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"062Ds2kL-2ta","executionInfo":{"status":"ok","timestamp":1627032233317,"user_tz":-60,"elapsed":23727,"user":{"displayName":"Diogo Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gim-qZpf2wH4mvH2DAEkLs8Y3EiDCq8ol8sQcqySQ=s64","userId":"00234577802052720177"}},"outputId":"abcacc02-bd02-46bf-f108-2958f4c58987"},"source":["'''\n","Mount Google Drive for COLAB\n","'''\n","\n","COLAB = True\n","\n","if COLAB:\n","  from google.colab import drive\n","  drive.mount('/content/gdrive', force_remount=True)\n","  %cd gdrive/My\\ Drive/Colab\\ Notebooks/Benchmark\n","  !pip install shap"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/Colab Notebooks/Benchmark\n","Collecting shap\n","  Downloading shap-0.39.0.tar.gz (356 kB)\n","\u001b[K     |████████████████████████████████| 356 kB 33.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (0.22.2.post1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.41.1)\n","Collecting slicer==0.0.7\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.2.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.0.1)\n","Building wheels for collected packages: shap\n","  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491650 sha256=2be20834dcd0083f84f2103c71a2bcffaf4ef91237c38cd0bcd4ece669606117\n","  Stored in directory: /root/.cache/pip/wheels/ca/25/8f/6ae5df62c32651cd719e972e738a8aaa4a87414c4d2b14c9c0\n","Successfully built shap\n","Installing collected packages: slicer, shap\n","Successfully installed shap-0.39.0 slicer-0.0.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"id":"NpO4Vl6m_LDB","executionInfo":{"status":"ok","timestamp":1627032239881,"user_tz":-60,"elapsed":365,"user":{"displayName":"Diogo Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gim-qZpf2wH4mvH2DAEkLs8Y3EiDCq8ol8sQcqySQ=s64","userId":"00234577802052720177"}},"outputId":"0ed91155-71ad-4278-eeb0-f279997bedf2"},"source":["import pandas as pd\n","df = pd.read_csv(r'results/Experiments_cnn_model.csv', index_col=['experiment'])\n","df['mean_loss'] = (df['mae_blind'] + df['rmse_blind'] + df['loss'] + df['mae'] + df['rmse'])/5\n","display(df.sort_values(['mean_loss']))"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>layers</th>\n","      <th>dropout_rate</th>\n","      <th>activation</th>\n","      <th>timesteps</th>\n","      <th>batch_size</th>\n","      <th>filters</th>\n","      <th>kernel_size</th>\n","      <th>pool_size</th>\n","      <th>epochs</th>\n","      <th>mae_blind</th>\n","      <th>rmse_blind</th>\n","      <th>loss</th>\n","      <th>mae</th>\n","      <th>rmse</th>\n","      <th>loss.1</th>\n","      <th>mae.1</th>\n","      <th>rmse.1</th>\n","      <th>train_time</th>\n","      <th>mean_loss</th>\n","    </tr>\n","    <tr>\n","      <th>experiment</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>126</th>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>tanh</td>\n","      <td>7</td>\n","      <td>20</td>\n","      <td>32</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>25</td>\n","      <td>0.148089</td>\n","      <td>0.173559</td>\n","      <td>0.038269</td>\n","      <td>0.025950</td>\n","      <td>0.038863</td>\n","      <td>[[0.22999752]]</td>\n","      <td>[[0.15595705]]</td>\n","      <td>[[0.23356634]]</td>\n","      <td>17.192366</td>\n","      <td>0.084946</td>\n","    </tr>\n","    <tr>\n","      <th>350</th>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>tanh</td>\n","      <td>7</td>\n","      <td>30</td>\n","      <td>32</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>25</td>\n","      <td>0.143444</td>\n","      <td>0.169081</td>\n","      <td>0.041282</td>\n","      <td>0.029328</td>\n","      <td>0.041735</td>\n","      <td>[[0.24810451]]</td>\n","      <td>[[0.17626111]]</td>\n","      <td>[[0.25082539]]</td>\n","      <td>13.383295</td>\n","      <td>0.084974</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>relu</td>\n","      <td>7</td>\n","      <td>10</td>\n","      <td>32</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>25</td>\n","      <td>0.151992</td>\n","      <td>0.176716</td>\n","      <td>0.037423</td>\n","      <td>0.025195</td>\n","      <td>0.038083</td>\n","      <td>[[0.22491258]]</td>\n","      <td>[[0.15142328]]</td>\n","      <td>[[0.2288815]]</td>\n","      <td>24.245493</td>\n","      <td>0.085882</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>relu</td>\n","      <td>7</td>\n","      <td>10</td>\n","      <td>32</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>25</td>\n","      <td>0.150791</td>\n","      <td>0.175682</td>\n","      <td>0.038572</td>\n","      <td>0.026045</td>\n","      <td>0.039223</td>\n","      <td>[[0.23181624]]</td>\n","      <td>[[0.15653031]]</td>\n","      <td>[[0.23572828]]</td>\n","      <td>21.466384</td>\n","      <td>0.086063</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>tanh</td>\n","      <td>7</td>\n","      <td>20</td>\n","      <td>64</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>25</td>\n","      <td>0.148496</td>\n","      <td>0.174695</td>\n","      <td>0.039964</td>\n","      <td>0.028095</td>\n","      <td>0.040506</td>\n","      <td>[[0.24018251]]</td>\n","      <td>[[0.16884888]]</td>\n","      <td>[[0.24344092]]</td>\n","      <td>17.486611</td>\n","      <td>0.086351</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>relu</td>\n","      <td>21</td>\n","      <td>10</td>\n","      <td>64</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>25</td>\n","      <td>0.270759</td>\n","      <td>0.291663</td>\n","      <td>0.065785</td>\n","      <td>0.052421</td>\n","      <td>0.065471</td>\n","      <td>[[0.3953705]]</td>\n","      <td>[[0.31504885]]</td>\n","      <td>[[0.39348042]]</td>\n","      <td>26.022124</td>\n","      <td>0.149220</td>\n","    </tr>\n","    <tr>\n","      <th>431</th>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>tanh</td>\n","      <td>21</td>\n","      <td>30</td>\n","      <td>64</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>25</td>\n","      <td>0.302388</td>\n","      <td>0.325200</td>\n","      <td>0.060003</td>\n","      <td>0.047466</td>\n","      <td>0.059605</td>\n","      <td>[[0.3606196]]</td>\n","      <td>[[0.28526884]]</td>\n","      <td>[[0.35822642]]</td>\n","      <td>12.958520</td>\n","      <td>0.158932</td>\n","    </tr>\n","    <tr>\n","      <th>427</th>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>tanh</td>\n","      <td>21</td>\n","      <td>30</td>\n","      <td>64</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>25</td>\n","      <td>0.305317</td>\n","      <td>0.328497</td>\n","      <td>0.059799</td>\n","      <td>0.047104</td>\n","      <td>0.059376</td>\n","      <td>[[0.35939103]]</td>\n","      <td>[[0.28309508]]</td>\n","      <td>[[0.35684871]]</td>\n","      <td>14.680101</td>\n","      <td>0.160018</td>\n","    </tr>\n","    <tr>\n","      <th>429</th>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>tanh</td>\n","      <td>21</td>\n","      <td>30</td>\n","      <td>64</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>25</td>\n","      <td>0.313761</td>\n","      <td>0.336902</td>\n","      <td>0.060808</td>\n","      <td>0.048132</td>\n","      <td>0.060391</td>\n","      <td>[[0.36545834]]</td>\n","      <td>[[0.28927145]]</td>\n","      <td>[[0.36295149]]</td>\n","      <td>12.856185</td>\n","      <td>0.163999</td>\n","    </tr>\n","    <tr>\n","      <th>391</th>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>tanh</td>\n","      <td>14</td>\n","      <td>30</td>\n","      <td>64</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>25</td>\n","      <td>0.315676</td>\n","      <td>0.336161</td>\n","      <td>0.059632</td>\n","      <td>0.049859</td>\n","      <td>0.060105</td>\n","      <td>[[0.35838772]]</td>\n","      <td>[[0.29965544]]</td>\n","      <td>[[0.36123249]]</td>\n","      <td>12.682738</td>\n","      <td>0.164287</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>433 rows × 19 columns</p>\n","</div>"],"text/plain":["            layers  dropout_rate  ... train_time  mean_loss\n","experiment                        ...                      \n","126              1           0.0  ...  17.192366   0.084946\n","350              1           0.5  ...  13.383295   0.084974\n","5                1           0.0  ...  24.245493   0.085882\n","2                1           0.0  ...  21.466384   0.086063\n","132              1           0.0  ...  17.486611   0.086351\n","...            ...           ...  ...        ...        ...\n","82               1           0.0  ...  26.022124   0.149220\n","431              1           0.5  ...  12.958520   0.158932\n","427              1           0.5  ...  14.680101   0.160018\n","429              1           0.5  ...  12.856185   0.163999\n","391              1           0.5  ...  12.682738   0.164287\n","\n","[433 rows x 19 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ptELzNpGCFKA","executionInfo":{"status":"ok","timestamp":1627032496717,"user_tz":-60,"elapsed":22573,"user":{"displayName":"Diogo Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gim-qZpf2wH4mvH2DAEkLs8Y3EiDCq8ol8sQcqySQ=s64","userId":"00234577802052720177"}},"outputId":"2b390520-0ba4-4894-bb05-fd803b5e7395"},"source":["SEED = 91195003\n","\n","import load_dataset as ld\n","import timeseries_preparation as tsp\n","import experiments as exp\n","import build_model as bm\n","import tensorflow as tf\n","from sklearn.model_selection import TimeSeriesSplit\n","import time\n","import numpy as np\n","\n","'''\n","Just load the dataset\n","'''\n","df_ph = ld.load_ph_dataset(univariate=True, colab=COLAB)\n","display(df_ph.sort_values(['value']))\n","\n","'''\n","Normalize it\n","'''\n","df_data = df_ph.copy()\n","scalers = tsp.data_normalization(df_data, norm_range=(0, 1))\n","\n","'''\n","Set the TimeSeries parameters\n","'''\n","multisteps = 2\n","cv_splits = 3\n","#must respect the name of the arguments of the build_model function\n","#timesteps are mandatory\n","hyperparameters = {\n","    'layers': [1],\n","    'dropout_rate': [0.0],\n","    'activation': ['tanh'],\n","    'timesteps': [7],\n","    'batch_size': [20],\n","    'filters': [32],\n","    'kernel_size': [6],\n","    'pool_size': [2],\n","}\n","callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=25, min_lr=0.00005),\n","             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, mode='min', verbose=0, patience=40)]\n","\n","param_list, param_names = exp.prepare_param_list(hyperparameters, bm.build_cnn_model)\n","model = exp.build_model(1, param_names, param_list[0], bm.build_cnn_model, SEED)\n","print(model.summary())\n","\n","X, y = tsp.to_supervised(df_data, param_list[0][param_names.index('timesteps')])\n","tscv = TimeSeriesSplit(n_splits=cv_splits)\n","for train_index, test_index in tscv.split(X):\n","  train_idx, val_idx = tsp.split_dataset(train_index, perc=10)\n","  X_train, y_train = X[train_idx], y[train_idx] \n","  X_val, y_val = X[val_idx], y[val_idx] \n","  X_test, y_test = X[test_index], y[test_index]\n","  if callbacks:\n","    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=25, batch_size=param_list[0][param_names.index('batch_size')], shuffle=False, verbose=1, callbacks=callbacks)\n","'''model_json = model.to_json()\n","print(model_json)\n","filename = 'models/lstm_' + time.strftime(\"%Y%m%d%H%M\") + '.h5'\n","model.save_weights(filename)'''"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>value</th>\n","    </tr>\n","    <tr>\n","      <th>timestep</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2017-11-01</th>\n","      <td>3.550</td>\n","    </tr>\n","    <tr>\n","      <th>2016-05-20</th>\n","      <td>4.040</td>\n","    </tr>\n","    <tr>\n","      <th>2016-05-04</th>\n","      <td>4.160</td>\n","    </tr>\n","    <tr>\n","      <th>2017-11-15</th>\n","      <td>4.165</td>\n","    </tr>\n","    <tr>\n","      <th>2017-12-15</th>\n","      <td>4.200</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-25</th>\n","      <td>8.800</td>\n","    </tr>\n","    <tr>\n","      <th>2019-04-11</th>\n","      <td>9.020</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-24</th>\n","      <td>9.040</td>\n","    </tr>\n","    <tr>\n","      <th>2019-10-30</th>\n","      <td>9.200</td>\n","    </tr>\n","    <tr>\n","      <th>2019-08-13</th>\n","      <td>9.560</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1610 rows × 1 columns</p>\n","</div>"],"text/plain":["            value\n","timestep         \n","2017-11-01  3.550\n","2016-05-20  4.040\n","2016-05-04  4.160\n","2017-11-15  4.165\n","2017-12-15  4.200\n","...           ...\n","2019-11-25  8.800\n","2019-04-11  9.020\n","2019-11-24  9.040\n","2019-10-30  9.200\n","2019-08-13  9.560\n","\n","[1610 rows x 1 columns]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Model: \"cnn_model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 7, 1)]            0         \n","_________________________________________________________________\n","conv1d (Conv1D)              (None, 2, 16)             112       \n","_________________________________________________________________\n","average_pooling1d (AveragePo (None, 1, 16)             0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 16)                0         \n","_________________________________________________________________\n","dense (Dense)                (None, 32)                544       \n","_________________________________________________________________\n","dropout (Dropout)            (None, 32)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 33        \n","=================================================================\n","Total params: 689\n","Trainable params: 689\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/25\n","19/19 [==============================] - 1s 13ms/step - loss: 0.2236 - mae: 0.2208 - rmse: 0.2189 - val_loss: 0.1059 - val_mae: 0.1041 - val_rmse: 0.1059\n","Epoch 2/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0619 - mae: 0.0519 - rmse: 0.0612 - val_loss: 0.0269 - val_mae: 0.0231 - val_rmse: 0.0269\n","Epoch 3/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 0.0301 - rmse: 0.0407 - val_loss: 0.0235 - val_mae: 0.0195 - val_rmse: 0.0235\n","Epoch 4/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0430 - mae: 0.0320 - rmse: 0.0424 - val_loss: 0.0296 - val_mae: 0.0258 - val_rmse: 0.0296\n","Epoch 5/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0456 - mae: 0.0347 - rmse: 0.0448 - val_loss: 0.0294 - val_mae: 0.0257 - val_rmse: 0.0294\n","Epoch 6/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0466 - mae: 0.0358 - rmse: 0.0459 - val_loss: 0.0273 - val_mae: 0.0236 - val_rmse: 0.0273\n","Epoch 7/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0469 - mae: 0.0362 - rmse: 0.0462 - val_loss: 0.0253 - val_mae: 0.0213 - val_rmse: 0.0253\n","Epoch 8/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0466 - mae: 0.0360 - rmse: 0.0461 - val_loss: 0.0240 - val_mae: 0.0199 - val_rmse: 0.0240\n","Epoch 9/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0463 - mae: 0.0356 - rmse: 0.0458 - val_loss: 0.0233 - val_mae: 0.0191 - val_rmse: 0.0233\n","Epoch 10/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0460 - mae: 0.0353 - rmse: 0.0455 - val_loss: 0.0229 - val_mae: 0.0186 - val_rmse: 0.0229\n","Epoch 11/25\n","19/19 [==============================] - 0s 2ms/step - loss: 0.0457 - mae: 0.0351 - rmse: 0.0453 - val_loss: 0.0226 - val_mae: 0.0181 - val_rmse: 0.0226\n","Epoch 12/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0455 - mae: 0.0349 - rmse: 0.0451 - val_loss: 0.0223 - val_mae: 0.0177 - val_rmse: 0.0223\n","Epoch 13/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0453 - mae: 0.0347 - rmse: 0.0449 - val_loss: 0.0220 - val_mae: 0.0174 - val_rmse: 0.0220\n","Epoch 14/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0451 - mae: 0.0345 - rmse: 0.0448 - val_loss: 0.0218 - val_mae: 0.0170 - val_rmse: 0.0218\n","Epoch 15/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0450 - mae: 0.0344 - rmse: 0.0446 - val_loss: 0.0217 - val_mae: 0.0168 - val_rmse: 0.0217\n","Epoch 16/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0448 - mae: 0.0342 - rmse: 0.0445 - val_loss: 0.0215 - val_mae: 0.0166 - val_rmse: 0.0215\n","Epoch 17/25\n","19/19 [==============================] - 0s 2ms/step - loss: 0.0447 - mae: 0.0341 - rmse: 0.0444 - val_loss: 0.0214 - val_mae: 0.0164 - val_rmse: 0.0214\n","Epoch 18/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0446 - mae: 0.0340 - rmse: 0.0443 - val_loss: 0.0213 - val_mae: 0.0162 - val_rmse: 0.0213\n","Epoch 19/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0444 - mae: 0.0338 - rmse: 0.0442 - val_loss: 0.0212 - val_mae: 0.0161 - val_rmse: 0.0212\n","Epoch 20/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0443 - mae: 0.0337 - rmse: 0.0441 - val_loss: 0.0212 - val_mae: 0.0160 - val_rmse: 0.0212\n","Epoch 21/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0442 - mae: 0.0336 - rmse: 0.0440 - val_loss: 0.0211 - val_mae: 0.0159 - val_rmse: 0.0211\n","Epoch 22/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0441 - mae: 0.0335 - rmse: 0.0439 - val_loss: 0.0210 - val_mae: 0.0159 - val_rmse: 0.0210\n","Epoch 23/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0440 - mae: 0.0334 - rmse: 0.0438 - val_loss: 0.0210 - val_mae: 0.0158 - val_rmse: 0.0210\n","Epoch 24/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0440 - mae: 0.0334 - rmse: 0.0437 - val_loss: 0.0209 - val_mae: 0.0158 - val_rmse: 0.0209\n","Epoch 25/25\n","19/19 [==============================] - 0s 3ms/step - loss: 0.0439 - mae: 0.0333 - rmse: 0.0437 - val_loss: 0.0209 - val_mae: 0.0157 - val_rmse: 0.0209\n","Epoch 1/25\n","37/37 [==============================] - 0s 3ms/step - loss: 0.0437 - mae: 0.0307 - rmse: 0.0432 - val_loss: 0.0360 - val_mae: 0.0232 - val_rmse: 0.0360\n","Epoch 2/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.0292 - rmse: 0.0412 - val_loss: 0.0351 - val_mae: 0.0213 - val_rmse: 0.0351\n","Epoch 3/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0425 - mae: 0.0298 - rmse: 0.0417 - val_loss: 0.0352 - val_mae: 0.0213 - val_rmse: 0.0352\n","Epoch 4/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0426 - mae: 0.0299 - rmse: 0.0419 - val_loss: 0.0352 - val_mae: 0.0215 - val_rmse: 0.0352\n","Epoch 5/25\n","37/37 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.0300 - rmse: 0.0420 - val_loss: 0.0353 - val_mae: 0.0218 - val_rmse: 0.0353\n","Epoch 6/25\n","37/37 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.0300 - rmse: 0.0421 - val_loss: 0.0354 - val_mae: 0.0221 - val_rmse: 0.0354\n","Epoch 7/25\n","37/37 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.0301 - rmse: 0.0421 - val_loss: 0.0355 - val_mae: 0.0224 - val_rmse: 0.0355\n","Epoch 8/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0428 - mae: 0.0300 - rmse: 0.0421 - val_loss: 0.0357 - val_mae: 0.0228 - val_rmse: 0.0357\n","Epoch 9/25\n","37/37 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.0300 - rmse: 0.0422 - val_loss: 0.0358 - val_mae: 0.0231 - val_rmse: 0.0358\n","Epoch 10/25\n","37/37 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.0300 - rmse: 0.0422 - val_loss: 0.0360 - val_mae: 0.0235 - val_rmse: 0.0360\n","Epoch 11/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0427 - mae: 0.0300 - rmse: 0.0422 - val_loss: 0.0362 - val_mae: 0.0239 - val_rmse: 0.0362\n","Epoch 12/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0426 - mae: 0.0299 - rmse: 0.0421 - val_loss: 0.0364 - val_mae: 0.0243 - val_rmse: 0.0364\n","Epoch 13/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0426 - mae: 0.0299 - rmse: 0.0421 - val_loss: 0.0365 - val_mae: 0.0246 - val_rmse: 0.0365\n","Epoch 14/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0426 - mae: 0.0299 - rmse: 0.0421 - val_loss: 0.0367 - val_mae: 0.0249 - val_rmse: 0.0367\n","Epoch 15/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0425 - mae: 0.0299 - rmse: 0.0421 - val_loss: 0.0368 - val_mae: 0.0252 - val_rmse: 0.0368\n","Epoch 16/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0425 - mae: 0.0298 - rmse: 0.0421 - val_loss: 0.0370 - val_mae: 0.0255 - val_rmse: 0.0370\n","Epoch 17/25\n","37/37 [==============================] - 0s 3ms/step - loss: 0.0424 - mae: 0.0298 - rmse: 0.0420 - val_loss: 0.0372 - val_mae: 0.0258 - val_rmse: 0.0372\n","Epoch 18/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0424 - mae: 0.0297 - rmse: 0.0420 - val_loss: 0.0374 - val_mae: 0.0261 - val_rmse: 0.0374\n","Epoch 19/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0423 - mae: 0.0297 - rmse: 0.0420 - val_loss: 0.0375 - val_mae: 0.0264 - val_rmse: 0.0375\n","Epoch 20/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0423 - mae: 0.0296 - rmse: 0.0419 - val_loss: 0.0377 - val_mae: 0.0267 - val_rmse: 0.0377\n","Epoch 21/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0422 - mae: 0.0296 - rmse: 0.0419 - val_loss: 0.0378 - val_mae: 0.0269 - val_rmse: 0.0378\n","Epoch 22/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0422 - mae: 0.0295 - rmse: 0.0418 - val_loss: 0.0379 - val_mae: 0.0271 - val_rmse: 0.0379\n","Epoch 23/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0421 - mae: 0.0295 - rmse: 0.0418 - val_loss: 0.0381 - val_mae: 0.0273 - val_rmse: 0.0381\n","Epoch 24/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0421 - mae: 0.0294 - rmse: 0.0418 - val_loss: 0.0382 - val_mae: 0.0275 - val_rmse: 0.0382\n","Epoch 25/25\n","37/37 [==============================] - 0s 2ms/step - loss: 0.0420 - mae: 0.0294 - rmse: 0.0417 - val_loss: 0.0383 - val_mae: 0.0277 - val_rmse: 0.0383\n","Epoch 1/25\n","55/55 [==============================] - 0s 3ms/step - loss: 0.0419 - mae: 0.0313 - rmse: 0.0422 - val_loss: 0.0363 - val_mae: 0.0263 - val_rmse: 0.0363\n","Epoch 2/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.0313 - rmse: 0.0422 - val_loss: 0.0339 - val_mae: 0.0235 - val_rmse: 0.0339\n","Epoch 3/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0416 - mae: 0.0310 - rmse: 0.0419 - val_loss: 0.0337 - val_mae: 0.0232 - val_rmse: 0.0337\n","Epoch 4/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0415 - mae: 0.0309 - rmse: 0.0418 - val_loss: 0.0336 - val_mae: 0.0232 - val_rmse: 0.0336\n","Epoch 5/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0414 - mae: 0.0308 - rmse: 0.0417 - val_loss: 0.0336 - val_mae: 0.0231 - val_rmse: 0.0336\n","Epoch 6/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0413 - mae: 0.0307 - rmse: 0.0416 - val_loss: 0.0335 - val_mae: 0.0230 - val_rmse: 0.0335\n","Epoch 7/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0413 - mae: 0.0306 - rmse: 0.0415 - val_loss: 0.0334 - val_mae: 0.0229 - val_rmse: 0.0334\n","Epoch 8/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0412 - mae: 0.0305 - rmse: 0.0414 - val_loss: 0.0334 - val_mae: 0.0228 - val_rmse: 0.0334\n","Epoch 9/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0411 - mae: 0.0304 - rmse: 0.0413 - val_loss: 0.0333 - val_mae: 0.0228 - val_rmse: 0.0333\n","Epoch 10/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0410 - mae: 0.0304 - rmse: 0.0413 - val_loss: 0.0333 - val_mae: 0.0227 - val_rmse: 0.0333\n","Epoch 11/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0410 - mae: 0.0303 - rmse: 0.0412 - val_loss: 0.0332 - val_mae: 0.0226 - val_rmse: 0.0332\n","Epoch 12/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0409 - mae: 0.0302 - rmse: 0.0411 - val_loss: 0.0332 - val_mae: 0.0226 - val_rmse: 0.0332\n","Epoch 13/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0408 - mae: 0.0301 - rmse: 0.0411 - val_loss: 0.0331 - val_mae: 0.0225 - val_rmse: 0.0331\n","Epoch 14/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0408 - mae: 0.0301 - rmse: 0.0410 - val_loss: 0.0330 - val_mae: 0.0225 - val_rmse: 0.0330\n","Epoch 15/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0408 - mae: 0.0302 - rmse: 0.0411 - val_loss: 0.0326 - val_mae: 0.0219 - val_rmse: 0.0326\n","Epoch 16/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0413 - mae: 0.0306 - rmse: 0.0416 - val_loss: 0.0346 - val_mae: 0.0244 - val_rmse: 0.0346\n","Epoch 17/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0406 - mae: 0.0298 - rmse: 0.0408 - val_loss: 0.0326 - val_mae: 0.0219 - val_rmse: 0.0326\n","Epoch 18/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0405 - mae: 0.0298 - rmse: 0.0407 - val_loss: 0.0329 - val_mae: 0.0223 - val_rmse: 0.0329\n","Epoch 19/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0404 - mae: 0.0297 - rmse: 0.0407 - val_loss: 0.0328 - val_mae: 0.0221 - val_rmse: 0.0328\n","Epoch 20/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0404 - mae: 0.0297 - rmse: 0.0406 - val_loss: 0.0328 - val_mae: 0.0221 - val_rmse: 0.0328\n","Epoch 21/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0403 - mae: 0.0296 - rmse: 0.0406 - val_loss: 0.0327 - val_mae: 0.0221 - val_rmse: 0.0327\n","Epoch 22/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0403 - mae: 0.0296 - rmse: 0.0405 - val_loss: 0.0327 - val_mae: 0.0220 - val_rmse: 0.0327\n","Epoch 23/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0402 - mae: 0.0295 - rmse: 0.0404 - val_loss: 0.0327 - val_mae: 0.0220 - val_rmse: 0.0327\n","Epoch 24/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0402 - mae: 0.0294 - rmse: 0.0404 - val_loss: 0.0326 - val_mae: 0.0219 - val_rmse: 0.0326\n","Epoch 25/25\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0401 - mae: 0.0294 - rmse: 0.0403 - val_loss: 0.0326 - val_mae: 0.0219 - val_rmse: 0.0326\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'model_json = model.to_json()\\nprint(model_json)\\nfilename = \\'models/lstm_\\' + time.strftime(\"%Y%m%d%H%M\") + \\'.h5\\'\\nmodel.save_weights(filename)'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":657},"id":"1c6J25PyODOA","executionInfo":{"status":"ok","timestamp":1627032530846,"user_tz":-60,"elapsed":574,"user":{"displayName":"Diogo Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gim-qZpf2wH4mvH2DAEkLs8Y3EiDCq8ol8sQcqySQ=s64","userId":"00234577802052720177"}},"outputId":"71df8bf9-2e2a-4806-f382-56c77cb68b41"},"source":["def recursive_forecast(model, X_test, y_test, timesteps, multisteps, features, scaler, col_target_position, evaluation_timesteps=30):\n","    targer_scaler = scaler['value']    \n","    input_seq = X_test[-evaluation_timesteps:, :, :]\n","    labels_seq = y_test[-evaluation_timesteps:, :]\n","    results = list()\n","    for i in range(len(input_seq)-(multisteps-1)):  #we cannot go through the entire input because we are multistep forecasting!\n","        inp = input_seq[i].copy()\n","        print(inp)\n","        lab = labels_seq[i].copy()\n","        #for each step of the multistep\n","        labels = list()\n","        predictions = list()\n","        for step in range(1, multisteps+1):\n","            #reshape\n","            inp = inp.reshape(1, timesteps, features)\n","            lab = lab.reshape(1, 1)\n","            #predict the value for the next timestep\n","            yhat = model.predict(inp, verbose=0)\n","            #invert normalized values\n","            lab_inversed = targer_scaler.inverse_transform(lab)\n","            yhat_inversed = targer_scaler.inverse_transform(yhat)\n","            #print(lab_inversed, yhat_inversed)\n","            #store results\n","            labels.append(lab_inversed[0][0])\n","            predictions.append(yhat_inversed[0][0])\n","            #insert a new value into the input sequence to predict the next timestep.\n","            if step != multisteps:\n","                #add yhat to the input sequence\n","                new_line = input_seq[i+step][-1].copy()\n","                np.put(new_line, col_target_position, yhat)\n","                new_line = new_line.reshape(1, features)\n","                inp = np.concatenate((inp[0], new_line))\n","                inp = inp[-timesteps:]\n","                #update label to the next timestep\n","                lab = labels_seq[i+step]\n","        results.append((np.array(predictions)))\n","    return np.array(results)\n","\n","#generated_data = np.random.uniform(low=6, high=9, size=9)\n","generated_data = [7.61, 7.075, 7.525, 6.9849, 7.105, 7.185, 7.04, 7.15, 7.165, 7.06]\n","generated_df = pd.DataFrame(generated_data, columns=['value'])\n","generated_df['value'] = scalers['value'].transform(generated_df[['value']])\n","X_generated, y_generated = tsp.to_supervised(generated_df , param_list[0][param_names.index('timesteps')])\n","generated_df['ph'] = scalers['value'].inverse_transform(generated_df[['value']])\n","display(generated_df)\n","print(recursive_forecast(model, X_generated, y_generated, param_list[0][param_names.index('timesteps')], 2, 1, scalers, generated_df.columns.get_loc('value')))"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>value</th>\n","      <th>ph</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.675541</td>\n","      <td>7.6100</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.586522</td>\n","      <td>7.0750</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.661398</td>\n","      <td>7.5250</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.571531</td>\n","      <td>6.9849</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.591514</td>\n","      <td>7.1050</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.604825</td>\n","      <td>7.1850</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.580699</td>\n","      <td>7.0400</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.599002</td>\n","      <td>7.1500</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.601498</td>\n","      <td>7.1650</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.584027</td>\n","      <td>7.0600</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      value      ph\n","0  0.675541  7.6100\n","1  0.586522  7.0750\n","2  0.661398  7.5250\n","3  0.571531  6.9849\n","4  0.591514  7.1050\n","5  0.604825  7.1850\n","6  0.580699  7.0400\n","7  0.599002  7.1500\n","8  0.601498  7.1650\n","9  0.584027  7.0600"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[[0.67554075]\n"," [0.58652246]\n"," [0.6613977 ]\n"," [0.57153076]\n"," [0.59151417]\n"," [0.6048253 ]\n"," [0.58069885]]\n","[[0.58652246]\n"," [0.6613977 ]\n"," [0.57153076]\n"," [0.59151417]\n"," [0.6048253 ]\n"," [0.58069885]\n"," [0.59900165]]\n","[[7.2576194 7.238274 ]\n"," [7.2209682 7.2423377]]\n"],"name":"stdout"}]}]}