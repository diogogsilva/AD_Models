{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tests2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMtyYaiVB0DfkvW0naMhWj/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"062Ds2kL-2ta","executionInfo":{"status":"ok","timestamp":1626877460937,"user_tz":-60,"elapsed":31306,"user":{"displayName":"Diogo Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gim-qZpf2wH4mvH2DAEkLs8Y3EiDCq8ol8sQcqySQ=s64","userId":"00234577802052720177"}},"outputId":"4ee4288c-4346-4514-d618-adadd0f8325c"},"source":["'''\n","Mount Google Drive for COLAB\n","'''\n","\n","COLAB = True\n","\n","if COLAB:\n","  from google.colab import drive\n","  drive.mount('/content/gdrive', force_remount=True)\n","  %cd gdrive/My\\ Drive/Colab\\ Notebooks/Benchmark\n","  !pip install shap"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/Colab Notebooks/Benchmark\n","Collecting shap\n","  Downloading shap-0.39.0.tar.gz (356 kB)\n","\u001b[K     |████████████████████████████████| 356 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (0.22.2.post1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.41.1)\n","Collecting slicer==0.0.7\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.2.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.0.1)\n","Building wheels for collected packages: shap\n","  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491656 sha256=f7068007776e8e830cd0d16848203ffd03d926e3a5f83a9c40d7c0886c8f7434\n","  Stored in directory: /root/.cache/pip/wheels/ca/25/8f/6ae5df62c32651cd719e972e738a8aaa4a87414c4d2b14c9c0\n","Successfully built shap\n","Installing collected packages: slicer, shap\n","Successfully installed shap-0.39.0 slicer-0.0.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"NpO4Vl6m_LDB","executionInfo":{"status":"ok","timestamp":1626877480322,"user_tz":-60,"elapsed":1642,"user":{"displayName":"Diogo Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gim-qZpf2wH4mvH2DAEkLs8Y3EiDCq8ol8sQcqySQ=s64","userId":"00234577802052720177"}},"outputId":"0954944c-85a6-4a8a-a851-155a652e4a7c"},"source":["import pandas as pd\n","df = pd.read_csv(r'results/Experiments_gru_model.csv', index_col=['experiment'])\n","df['mean_loss'] = (df['mae_blind'] + df['rmse_blind'] + df['loss'] + df['mae'] + df['rmse'])/5\n","display(df.sort_values(['mean_loss']))"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>layers</th>\n","      <th>neurons</th>\n","      <th>dropout_rate</th>\n","      <th>activation</th>\n","      <th>timesteps</th>\n","      <th>batch_size</th>\n","      <th>epochs</th>\n","      <th>mae_blind</th>\n","      <th>rmse_blind</th>\n","      <th>loss</th>\n","      <th>mae</th>\n","      <th>rmse</th>\n","      <th>loss.1</th>\n","      <th>mae.1</th>\n","      <th>rmse.1</th>\n","      <th>train_time</th>\n","      <th>mean_loss</th>\n","    </tr>\n","    <tr>\n","      <th>experiment</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>174</th>\n","      <td>2</td>\n","      <td>64</td>\n","      <td>0.5</td>\n","      <td>tanh</td>\n","      <td>7</td>\n","      <td>30</td>\n","      <td>50</td>\n","      <td>0.151101</td>\n","      <td>0.176317</td>\n","      <td>0.038832</td>\n","      <td>0.027015</td>\n","      <td>0.039428</td>\n","      <td>[[0.23337991]]</td>\n","      <td>[[0.16235737]]</td>\n","      <td>[[0.23696452]]</td>\n","      <td>37.453078</td>\n","      <td>0.086538</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>1</td>\n","      <td>32</td>\n","      <td>0.5</td>\n","      <td>tanh</td>\n","      <td>7</td>\n","      <td>20</td>\n","      <td>50</td>\n","      <td>0.152267</td>\n","      <td>0.177366</td>\n","      <td>0.038185</td>\n","      <td>0.026345</td>\n","      <td>0.038808</td>\n","      <td>[[0.22949118]]</td>\n","      <td>[[0.15833411]]</td>\n","      <td>[[0.23323546]]</td>\n","      <td>36.161893</td>\n","      <td>0.086594</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>1</td>\n","      <td>64</td>\n","      <td>0.5</td>\n","      <td>relu</td>\n","      <td>7</td>\n","      <td>20</td>\n","      <td>50</td>\n","      <td>0.151438</td>\n","      <td>0.177035</td>\n","      <td>0.039748</td>\n","      <td>0.028193</td>\n","      <td>0.040280</td>\n","      <td>[[0.2388833]]</td>\n","      <td>[[0.16943808]]</td>\n","      <td>[[0.24208209]]</td>\n","      <td>30.180098</td>\n","      <td>0.087339</td>\n","    </tr>\n","    <tr>\n","      <th>165</th>\n","      <td>2</td>\n","      <td>64</td>\n","      <td>0.5</td>\n","      <td>relu</td>\n","      <td>7</td>\n","      <td>30</td>\n","      <td>50</td>\n","      <td>0.152134</td>\n","      <td>0.177910</td>\n","      <td>0.039416</td>\n","      <td>0.027728</td>\n","      <td>0.039948</td>\n","      <td>[[0.23689195]]</td>\n","      <td>[[0.16664406]]</td>\n","      <td>[[0.24008664]]</td>\n","      <td>42.948302</td>\n","      <td>0.087427</td>\n","    </tr>\n","    <tr>\n","      <th>136</th>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>0.5</td>\n","      <td>tanh</td>\n","      <td>7</td>\n","      <td>10</td>\n","      <td>50</td>\n","      <td>0.155650</td>\n","      <td>0.180757</td>\n","      <td>0.038402</td>\n","      <td>0.026283</td>\n","      <td>0.039074</td>\n","      <td>[[0.2307988]]</td>\n","      <td>[[0.15795949]]</td>\n","      <td>[[0.23483386]]</td>\n","      <td>66.661638</td>\n","      <td>0.088033</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>143</th>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>0.5</td>\n","      <td>tanh</td>\n","      <td>21</td>\n","      <td>20</td>\n","      <td>50</td>\n","      <td>0.208130</td>\n","      <td>0.230228</td>\n","      <td>0.044343</td>\n","      <td>0.030492</td>\n","      <td>0.044083</td>\n","      <td>[[0.2665043]]</td>\n","      <td>[[0.1832589]]</td>\n","      <td>[[0.26494109]]</td>\n","      <td>53.066998</td>\n","      <td>0.111456</td>\n","    </tr>\n","    <tr>\n","      <th>170</th>\n","      <td>2</td>\n","      <td>64</td>\n","      <td>0.5</td>\n","      <td>relu</td>\n","      <td>21</td>\n","      <td>20</td>\n","      <td>50</td>\n","      <td>0.208440</td>\n","      <td>0.230444</td>\n","      <td>0.045079</td>\n","      <td>0.030994</td>\n","      <td>0.044833</td>\n","      <td>[[0.27092355]]</td>\n","      <td>[[0.1862763]]</td>\n","      <td>[[0.26944601]]</td>\n","      <td>45.717453</td>\n","      <td>0.111958</td>\n","    </tr>\n","    <tr>\n","      <th>141</th>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>0.5</td>\n","      <td>tanh</td>\n","      <td>14</td>\n","      <td>30</td>\n","      <td>50</td>\n","      <td>0.216873</td>\n","      <td>0.237639</td>\n","      <td>0.044747</td>\n","      <td>0.032538</td>\n","      <td>0.045486</td>\n","      <td>[[0.26893061]]</td>\n","      <td>[[0.19555498]]</td>\n","      <td>[[0.27336854]]</td>\n","      <td>40.271136</td>\n","      <td>0.115457</td>\n","    </tr>\n","    <tr>\n","      <th>189</th>\n","      <td>2</td>\n","      <td>128</td>\n","      <td>0.0</td>\n","      <td>relu</td>\n","      <td>21</td>\n","      <td>30</td>\n","      <td>50</td>\n","      <td>0.215461</td>\n","      <td>0.238994</td>\n","      <td>0.046081</td>\n","      <td>0.032651</td>\n","      <td>0.045763</td>\n","      <td>[[0.27694563]]</td>\n","      <td>[[0.19622981]]</td>\n","      <td>[[0.27503506]]</td>\n","      <td>42.096978</td>\n","      <td>0.115790</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>1</td>\n","      <td>64</td>\n","      <td>0.5</td>\n","      <td>tanh</td>\n","      <td>21</td>\n","      <td>20</td>\n","      <td>50</td>\n","      <td>0.228795</td>\n","      <td>0.251499</td>\n","      <td>0.046550</td>\n","      <td>0.033299</td>\n","      <td>0.046240</td>\n","      <td>[[0.2797634]]</td>\n","      <td>[[0.2001286]]</td>\n","      <td>[[0.27790225]]</td>\n","      <td>28.817647</td>\n","      <td>0.121277</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>216 rows × 17 columns</p>\n","</div>"],"text/plain":["            layers  neurons  ...  train_time mean_loss\n","experiment                   ...                      \n","174              2       64  ...   37.453078  0.086538\n","29               1       32  ...   36.161893  0.086594\n","56               1       64  ...   30.180098  0.087339\n","165              2       64  ...   42.948302  0.087427\n","136              2       32  ...   66.661638  0.088033\n","...            ...      ...  ...         ...       ...\n","143              2       32  ...   53.066998  0.111456\n","170              2       64  ...   45.717453  0.111958\n","141              2       32  ...   40.271136  0.115457\n","189              2      128  ...   42.096978  0.115790\n","71               1       64  ...   28.817647  0.121277\n","\n","[216 rows x 17 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ptELzNpGCFKA","executionInfo":{"status":"ok","timestamp":1626877638094,"user_tz":-60,"elapsed":67735,"user":{"displayName":"Diogo Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gim-qZpf2wH4mvH2DAEkLs8Y3EiDCq8ol8sQcqySQ=s64","userId":"00234577802052720177"}},"outputId":"8eeb7678-745e-4440-ba5c-186fc672999b"},"source":["SEED = 91195003\n","\n","import load_dataset as ld\n","import timeseries_preparation as tsp\n","import experiments as exp\n","import build_model as bm\n","import tensorflow as tf\n","from sklearn.model_selection import TimeSeriesSplit\n","import time\n","import numpy as np\n","\n","'''\n","Just load the dataset\n","'''\n","df_ph = ld.load_ph_dataset(univariate=True, colab=COLAB)\n","display(df_ph.sort_values(['value']))\n","\n","'''\n","Normalize it\n","'''\n","df_data = df_ph.copy()\n","scalers = tsp.data_normalization(df_data, norm_range=(0, 1))\n","\n","'''\n","Set the TimeSeries parameters\n","'''\n","multisteps = 2\n","cv_splits = 3\n","#must respect the name of the arguments of the build_model function\n","#timesteps are mandatory\n","hyperparameters = {\n","    'layers': [2],\n","    'neurons': [64],\n","    'dropout_rate': [0.5],\n","    'activation': ['tanh'],\n","    'timesteps': [7],\n","    'batch_size': [30]\n","}\n","callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=25, min_lr=0.00005),\n","             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, mode='min', verbose=0, patience=40)]\n","\n","param_list, param_names = exp.prepare_param_list(hyperparameters, bm.build_gru_model)\n","model = exp.build_model(1, param_names, param_list[0], bm.build_gru_model, SEED)\n","print(model.summary())\n","\n","X, y = tsp.to_supervised(df_data, param_list[0][param_names.index('timesteps')])\n","tscv = TimeSeriesSplit(n_splits=cv_splits)\n","for train_index, test_index in tscv.split(X):\n","  train_idx, val_idx = tsp.split_dataset(train_index, perc=10)\n","  X_train, y_train = X[train_idx], y[train_idx] \n","  X_val, y_val = X[val_idx], y[val_idx] \n","  X_test, y_test = X[test_index], y[test_index]\n","  if callbacks:\n","    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=param_list[0][param_names.index('batch_size')], shuffle=False, verbose=1, callbacks=callbacks)\n","'''model_json = model.to_json()\n","print(model_json)\n","filename = 'models/lstm_' + time.strftime(\"%Y%m%d%H%M\") + '.h5'\n","model.save_weights(filename)'''"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>value</th>\n","    </tr>\n","    <tr>\n","      <th>timestep</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2017-11-01</th>\n","      <td>3.550</td>\n","    </tr>\n","    <tr>\n","      <th>2016-05-20</th>\n","      <td>4.040</td>\n","    </tr>\n","    <tr>\n","      <th>2016-05-04</th>\n","      <td>4.160</td>\n","    </tr>\n","    <tr>\n","      <th>2017-11-15</th>\n","      <td>4.165</td>\n","    </tr>\n","    <tr>\n","      <th>2017-12-15</th>\n","      <td>4.200</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-25</th>\n","      <td>8.800</td>\n","    </tr>\n","    <tr>\n","      <th>2019-04-11</th>\n","      <td>9.020</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-24</th>\n","      <td>9.040</td>\n","    </tr>\n","    <tr>\n","      <th>2019-10-30</th>\n","      <td>9.200</td>\n","    </tr>\n","    <tr>\n","      <th>2019-08-13</th>\n","      <td>9.560</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1610 rows × 1 columns</p>\n","</div>"],"text/plain":["            value\n","timestep         \n","2017-11-01  3.550\n","2016-05-20  4.040\n","2016-05-04  4.160\n","2017-11-15  4.165\n","2017-12-15  4.200\n","...           ...\n","2019-11-25  8.800\n","2019-04-11  9.020\n","2019-11-24  9.040\n","2019-10-30  9.200\n","2019-08-13  9.560\n","\n","[1610 rows x 1 columns]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Model: \"gru_model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 7, 1)]            0         \n","_________________________________________________________________\n","gru (GRU)                    (None, 7, 64)             12864     \n","_________________________________________________________________\n","gru_1 (GRU)                  (None, 128)               74496     \n","_________________________________________________________________\n","dense (Dense)                (None, 64)                8256      \n","_________________________________________________________________\n","dropout (Dropout)            (None, 64)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 95,681\n","Trainable params: 95,681\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","13/13 [==============================] - 10s 77ms/step - loss: 0.2695 - mae: 0.2458 - rmse: 0.2583 - val_loss: 0.1511 - val_mae: 0.1500 - val_rmse: 0.1454\n","Epoch 2/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.1321 - mae: 0.1068 - rmse: 0.1260 - val_loss: 0.0667 - val_mae: 0.0640 - val_rmse: 0.0616\n","Epoch 3/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.1145 - mae: 0.0926 - rmse: 0.1118 - val_loss: 0.0245 - val_mae: 0.0210 - val_rmse: 0.0278\n","Epoch 4/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.1117 - mae: 0.0886 - rmse: 0.1056 - val_loss: 0.0259 - val_mae: 0.0223 - val_rmse: 0.0295\n","Epoch 5/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.1014 - mae: 0.0802 - rmse: 0.1014 - val_loss: 0.0301 - val_mae: 0.0262 - val_rmse: 0.0341\n","Epoch 6/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.1123 - mae: 0.0886 - rmse: 0.1115 - val_loss: 0.0223 - val_mae: 0.0179 - val_rmse: 0.0215\n","Epoch 7/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.1047 - mae: 0.0819 - rmse: 0.1057 - val_loss: 0.0268 - val_mae: 0.0219 - val_rmse: 0.0240\n","Epoch 8/50\n","13/13 [==============================] - 0s 12ms/step - loss: 0.1005 - mae: 0.0802 - rmse: 0.0980 - val_loss: 0.0212 - val_mae: 0.0170 - val_rmse: 0.0212\n","Epoch 9/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.1075 - mae: 0.0860 - rmse: 0.1081 - val_loss: 0.0442 - val_mae: 0.0400 - val_rmse: 0.0486\n","Epoch 10/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.1097 - mae: 0.0893 - rmse: 0.1175 - val_loss: 0.0418 - val_mae: 0.0375 - val_rmse: 0.0461\n","Epoch 11/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.1066 - mae: 0.0842 - rmse: 0.1024 - val_loss: 0.0636 - val_mae: 0.0607 - val_rmse: 0.0681\n","Epoch 12/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.1108 - mae: 0.0869 - rmse: 0.1068 - val_loss: 0.0391 - val_mae: 0.0348 - val_rmse: 0.0433\n","Epoch 13/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.1013 - mae: 0.0790 - rmse: 0.0988 - val_loss: 0.0250 - val_mae: 0.0216 - val_rmse: 0.0284\n","Epoch 14/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0995 - mae: 0.0806 - rmse: 0.0979 - val_loss: 0.0303 - val_mae: 0.0265 - val_rmse: 0.0341\n","Epoch 15/50\n","13/13 [==============================] - 0s 12ms/step - loss: 0.0939 - mae: 0.0754 - rmse: 0.0930 - val_loss: 0.0322 - val_mae: 0.0282 - val_rmse: 0.0361\n","Epoch 16/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.1039 - mae: 0.0828 - rmse: 0.1132 - val_loss: 0.0311 - val_mae: 0.0272 - val_rmse: 0.0349\n","Epoch 17/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0977 - mae: 0.0776 - rmse: 0.0916 - val_loss: 0.0549 - val_mae: 0.0514 - val_rmse: 0.0591\n","Epoch 18/50\n","13/13 [==============================] - 0s 9ms/step - loss: 0.0979 - mae: 0.0778 - rmse: 0.0942 - val_loss: 0.0207 - val_mae: 0.0165 - val_rmse: 0.0222\n","Epoch 19/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0943 - mae: 0.0732 - rmse: 0.0935 - val_loss: 0.0211 - val_mae: 0.0169 - val_rmse: 0.0209\n","Epoch 20/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0905 - mae: 0.0720 - rmse: 0.0876 - val_loss: 0.0206 - val_mae: 0.0163 - val_rmse: 0.0217\n","Epoch 21/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0907 - mae: 0.0723 - rmse: 0.0897 - val_loss: 0.0226 - val_mae: 0.0180 - val_rmse: 0.0213\n","Epoch 22/50\n","13/13 [==============================] - 0s 11ms/step - loss: 0.0879 - mae: 0.0682 - rmse: 0.0897 - val_loss: 0.0357 - val_mae: 0.0314 - val_rmse: 0.0395\n","Epoch 23/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0975 - mae: 0.0759 - rmse: 0.0935 - val_loss: 0.0307 - val_mae: 0.0268 - val_rmse: 0.0343\n","Epoch 24/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0921 - mae: 0.0732 - rmse: 0.0929 - val_loss: 0.0243 - val_mae: 0.0209 - val_rmse: 0.0272\n","Epoch 25/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0830 - mae: 0.0654 - rmse: 0.0794 - val_loss: 0.0280 - val_mae: 0.0243 - val_rmse: 0.0313\n","Epoch 26/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0923 - mae: 0.0731 - rmse: 0.0962 - val_loss: 0.0319 - val_mae: 0.0279 - val_rmse: 0.0354\n","Epoch 27/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0932 - mae: 0.0737 - rmse: 0.0942 - val_loss: 0.0430 - val_mae: 0.0387 - val_rmse: 0.0469\n","Epoch 28/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0926 - mae: 0.0727 - rmse: 0.0887 - val_loss: 0.0285 - val_mae: 0.0248 - val_rmse: 0.0319\n","Epoch 29/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0897 - mae: 0.0697 - rmse: 0.0924 - val_loss: 0.0478 - val_mae: 0.0436 - val_rmse: 0.0516\n","Epoch 30/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0857 - mae: 0.0677 - rmse: 0.0850 - val_loss: 0.0272 - val_mae: 0.0236 - val_rmse: 0.0303\n","Epoch 31/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0825 - mae: 0.0636 - rmse: 0.0809 - val_loss: 0.0263 - val_mae: 0.0227 - val_rmse: 0.0292\n","Epoch 32/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0892 - mae: 0.0689 - rmse: 0.0867 - val_loss: 0.0223 - val_mae: 0.0177 - val_rmse: 0.0211\n","Epoch 33/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0845 - mae: 0.0643 - rmse: 0.0802 - val_loss: 0.0237 - val_mae: 0.0187 - val_rmse: 0.0218\n","Epoch 34/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0925 - mae: 0.0728 - rmse: 0.0891 - val_loss: 0.0246 - val_mae: 0.0211 - val_rmse: 0.0274\n","Epoch 35/50\n","13/13 [==============================] - 0s 11ms/step - loss: 0.0894 - mae: 0.0689 - rmse: 0.0882 - val_loss: 0.0363 - val_mae: 0.0320 - val_rmse: 0.0399\n","Epoch 36/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0859 - mae: 0.0662 - rmse: 0.0874 - val_loss: 0.0462 - val_mae: 0.0419 - val_rmse: 0.0499\n","Epoch 37/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0912 - mae: 0.0727 - rmse: 0.0877 - val_loss: 0.0221 - val_mae: 0.0185 - val_rmse: 0.0243\n","Epoch 38/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0839 - mae: 0.0643 - rmse: 0.0835 - val_loss: 0.0232 - val_mae: 0.0197 - val_rmse: 0.0256\n","Epoch 39/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0826 - mae: 0.0636 - rmse: 0.0827 - val_loss: 0.0206 - val_mae: 0.0164 - val_rmse: 0.0208\n","Epoch 40/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0883 - mae: 0.0683 - rmse: 0.0913 - val_loss: 0.0209 - val_mae: 0.0169 - val_rmse: 0.0223\n","Epoch 41/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0854 - mae: 0.0656 - rmse: 0.0875 - val_loss: 0.0433 - val_mae: 0.0389 - val_rmse: 0.0468\n","Epoch 42/50\n","13/13 [==============================] - 0s 11ms/step - loss: 0.0845 - mae: 0.0657 - rmse: 0.0834 - val_loss: 0.0334 - val_mae: 0.0292 - val_rmse: 0.0366\n","Epoch 43/50\n","13/13 [==============================] - 0s 10ms/step - loss: 0.0773 - mae: 0.0586 - rmse: 0.0768 - val_loss: 0.0246 - val_mae: 0.0197 - val_rmse: 0.0225\n","Epoch 1/50\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0830 - mae: 0.0630 - rmse: 0.0839 - val_loss: 0.0415 - val_mae: 0.0326 - val_rmse: 0.0425\n","Epoch 2/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0818 - mae: 0.0622 - rmse: 0.0807 - val_loss: 0.0388 - val_mae: 0.0290 - val_rmse: 0.0399\n","Epoch 3/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0808 - mae: 0.0623 - rmse: 0.0810 - val_loss: 0.0501 - val_mae: 0.0430 - val_rmse: 0.0510\n","Epoch 4/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0799 - mae: 0.0612 - rmse: 0.0785 - val_loss: 0.0330 - val_mae: 0.0219 - val_rmse: 0.0345\n","Epoch 5/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0748 - mae: 0.0561 - rmse: 0.0738 - val_loss: 0.0375 - val_mae: 0.0275 - val_rmse: 0.0386\n","Epoch 6/50\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0812 - mae: 0.0616 - rmse: 0.0799 - val_loss: 0.0394 - val_mae: 0.0298 - val_rmse: 0.0404\n","Epoch 7/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0769 - mae: 0.0571 - rmse: 0.0764 - val_loss: 0.0341 - val_mae: 0.0235 - val_rmse: 0.0354\n","Epoch 8/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0823 - mae: 0.0636 - rmse: 0.0834 - val_loss: 0.0480 - val_mae: 0.0403 - val_rmse: 0.0489\n","Epoch 9/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0786 - mae: 0.0587 - rmse: 0.0777 - val_loss: 0.0433 - val_mae: 0.0348 - val_rmse: 0.0443\n","Epoch 10/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0745 - mae: 0.0559 - rmse: 0.0738 - val_loss: 0.0458 - val_mae: 0.0378 - val_rmse: 0.0468\n","Epoch 11/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0758 - mae: 0.0568 - rmse: 0.0740 - val_loss: 0.0411 - val_mae: 0.0321 - val_rmse: 0.0421\n","Epoch 12/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0760 - mae: 0.0577 - rmse: 0.0752 - val_loss: 0.0380 - val_mae: 0.0282 - val_rmse: 0.0392\n","Epoch 13/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0746 - mae: 0.0566 - rmse: 0.0725 - val_loss: 0.0514 - val_mae: 0.0446 - val_rmse: 0.0524\n","Epoch 14/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0708 - mae: 0.0530 - rmse: 0.0709 - val_loss: 0.0349 - val_mae: 0.0248 - val_rmse: 0.0362\n","Epoch 15/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0749 - mae: 0.0565 - rmse: 0.0748 - val_loss: 0.0449 - val_mae: 0.0367 - val_rmse: 0.0458\n","Epoch 16/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0737 - mae: 0.0561 - rmse: 0.0736 - val_loss: 0.0452 - val_mae: 0.0371 - val_rmse: 0.0462\n","Epoch 17/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0741 - mae: 0.0559 - rmse: 0.0731 - val_loss: 0.0345 - val_mae: 0.0241 - val_rmse: 0.0358\n","Epoch 18/50\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0724 - mae: 0.0532 - rmse: 0.0719 - val_loss: 0.0348 - val_mae: 0.0243 - val_rmse: 0.0361\n","Epoch 19/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0706 - mae: 0.0524 - rmse: 0.0697 - val_loss: 0.0348 - val_mae: 0.0243 - val_rmse: 0.0361\n","Epoch 20/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0680 - mae: 0.0513 - rmse: 0.0673 - val_loss: 0.0390 - val_mae: 0.0295 - val_rmse: 0.0402\n","Epoch 21/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0686 - mae: 0.0515 - rmse: 0.0665 - val_loss: 0.0387 - val_mae: 0.0290 - val_rmse: 0.0398\n","Epoch 22/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0673 - mae: 0.0498 - rmse: 0.0666 - val_loss: 0.0374 - val_mae: 0.0273 - val_rmse: 0.0386\n","Epoch 23/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0670 - mae: 0.0488 - rmse: 0.0672 - val_loss: 0.0429 - val_mae: 0.0345 - val_rmse: 0.0440\n","Epoch 24/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0675 - mae: 0.0493 - rmse: 0.0688 - val_loss: 0.0409 - val_mae: 0.0321 - val_rmse: 0.0421\n","Epoch 25/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0665 - mae: 0.0484 - rmse: 0.0666 - val_loss: 0.0355 - val_mae: 0.0248 - val_rmse: 0.0368\n","Epoch 26/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0643 - mae: 0.0478 - rmse: 0.0637 - val_loss: 0.0464 - val_mae: 0.0389 - val_rmse: 0.0475\n","Epoch 27/50\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0688 - mae: 0.0505 - rmse: 0.0670 - val_loss: 0.0460 - val_mae: 0.0385 - val_rmse: 0.0472\n","Epoch 28/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0651 - mae: 0.0476 - rmse: 0.0637 - val_loss: 0.0339 - val_mae: 0.0232 - val_rmse: 0.0353\n","Epoch 29/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0639 - mae: 0.0469 - rmse: 0.0629 - val_loss: 0.0384 - val_mae: 0.0287 - val_rmse: 0.0395\n","Epoch 30/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0633 - mae: 0.0459 - rmse: 0.0634 - val_loss: 0.0389 - val_mae: 0.0293 - val_rmse: 0.0400\n","Epoch 31/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0589 - mae: 0.0432 - rmse: 0.0570 - val_loss: 0.0371 - val_mae: 0.0269 - val_rmse: 0.0383\n","Epoch 32/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0616 - mae: 0.0456 - rmse: 0.0607 - val_loss: 0.0374 - val_mae: 0.0274 - val_rmse: 0.0386\n","Epoch 33/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0610 - mae: 0.0445 - rmse: 0.0612 - val_loss: 0.0365 - val_mae: 0.0263 - val_rmse: 0.0378\n","Epoch 34/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0623 - mae: 0.0451 - rmse: 0.0618 - val_loss: 0.0374 - val_mae: 0.0275 - val_rmse: 0.0387\n","Epoch 35/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0611 - mae: 0.0444 - rmse: 0.0600 - val_loss: 0.0351 - val_mae: 0.0244 - val_rmse: 0.0365\n","Epoch 36/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0617 - mae: 0.0445 - rmse: 0.0606 - val_loss: 0.0378 - val_mae: 0.0280 - val_rmse: 0.0391\n","Epoch 37/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0608 - mae: 0.0443 - rmse: 0.0606 - val_loss: 0.0354 - val_mae: 0.0248 - val_rmse: 0.0368\n","Epoch 38/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0600 - mae: 0.0435 - rmse: 0.0593 - val_loss: 0.0343 - val_mae: 0.0233 - val_rmse: 0.0358\n","Epoch 39/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0607 - mae: 0.0436 - rmse: 0.0593 - val_loss: 0.0351 - val_mae: 0.0245 - val_rmse: 0.0366\n","Epoch 40/50\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0593 - mae: 0.0425 - rmse: 0.0574 - val_loss: 0.0352 - val_mae: 0.0246 - val_rmse: 0.0366\n","Epoch 41/50\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0613 - mae: 0.0442 - rmse: 0.0603 - val_loss: 0.0342 - val_mae: 0.0231 - val_rmse: 0.0357\n","Epoch 1/50\n","37/37 [==============================] - 1s 31ms/step - loss: 0.0573 - mae: 0.0430 - rmse: 0.0563 - val_loss: 0.0329 - val_mae: 0.0201 - val_rmse: 0.0329\n","Epoch 2/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0559 - mae: 0.0412 - rmse: 0.0553 - val_loss: 0.0328 - val_mae: 0.0199 - val_rmse: 0.0328\n","Epoch 3/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0541 - mae: 0.0409 - rmse: 0.0539 - val_loss: 0.0328 - val_mae: 0.0199 - val_rmse: 0.0328\n","Epoch 4/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0565 - mae: 0.0415 - rmse: 0.0575 - val_loss: 0.0330 - val_mae: 0.0203 - val_rmse: 0.0330\n","Epoch 5/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0559 - mae: 0.0413 - rmse: 0.0563 - val_loss: 0.0332 - val_mae: 0.0200 - val_rmse: 0.0332\n","Epoch 6/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0563 - mae: 0.0421 - rmse: 0.0560 - val_loss: 0.0328 - val_mae: 0.0198 - val_rmse: 0.0328\n","Epoch 7/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0562 - mae: 0.0417 - rmse: 0.0563 - val_loss: 0.0332 - val_mae: 0.0204 - val_rmse: 0.0332\n","Epoch 8/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0571 - mae: 0.0421 - rmse: 0.0569 - val_loss: 0.0337 - val_mae: 0.0211 - val_rmse: 0.0337\n","Epoch 9/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0551 - mae: 0.0408 - rmse: 0.0561 - val_loss: 0.0335 - val_mae: 0.0209 - val_rmse: 0.0335\n","Epoch 10/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0569 - mae: 0.0417 - rmse: 0.0566 - val_loss: 0.0327 - val_mae: 0.0196 - val_rmse: 0.0327\n","Epoch 11/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0544 - mae: 0.0399 - rmse: 0.0547 - val_loss: 0.0328 - val_mae: 0.0196 - val_rmse: 0.0328\n","Epoch 12/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0535 - mae: 0.0390 - rmse: 0.0522 - val_loss: 0.0334 - val_mae: 0.0208 - val_rmse: 0.0334\n","Epoch 13/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0550 - mae: 0.0403 - rmse: 0.0557 - val_loss: 0.0334 - val_mae: 0.0207 - val_rmse: 0.0334\n","Epoch 14/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0550 - mae: 0.0411 - rmse: 0.0553 - val_loss: 0.0327 - val_mae: 0.0198 - val_rmse: 0.0327\n","Epoch 15/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0534 - mae: 0.0390 - rmse: 0.0551 - val_loss: 0.0334 - val_mae: 0.0208 - val_rmse: 0.0334\n","Epoch 16/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0548 - mae: 0.0402 - rmse: 0.0545 - val_loss: 0.0332 - val_mae: 0.0205 - val_rmse: 0.0332\n","Epoch 17/50\n","37/37 [==============================] - 0s 10ms/step - loss: 0.0555 - mae: 0.0405 - rmse: 0.0545 - val_loss: 0.0327 - val_mae: 0.0197 - val_rmse: 0.0327\n","Epoch 18/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0528 - mae: 0.0395 - rmse: 0.0523 - val_loss: 0.0339 - val_mae: 0.0213 - val_rmse: 0.0339\n","Epoch 19/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0534 - mae: 0.0391 - rmse: 0.0537 - val_loss: 0.0328 - val_mae: 0.0200 - val_rmse: 0.0328\n","Epoch 20/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0544 - mae: 0.0399 - rmse: 0.0542 - val_loss: 0.0328 - val_mae: 0.0199 - val_rmse: 0.0328\n","Epoch 21/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0531 - mae: 0.0388 - rmse: 0.0536 - val_loss: 0.0327 - val_mae: 0.0198 - val_rmse: 0.0327\n","Epoch 22/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0531 - mae: 0.0392 - rmse: 0.0522 - val_loss: 0.0333 - val_mae: 0.0207 - val_rmse: 0.0333\n","Epoch 23/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0518 - mae: 0.0373 - rmse: 0.0518 - val_loss: 0.0327 - val_mae: 0.0198 - val_rmse: 0.0327\n","Epoch 24/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0520 - mae: 0.0381 - rmse: 0.0519 - val_loss: 0.0329 - val_mae: 0.0201 - val_rmse: 0.0329\n","Epoch 25/50\n","37/37 [==============================] - 0s 10ms/step - loss: 0.0528 - mae: 0.0382 - rmse: 0.0535 - val_loss: 0.0327 - val_mae: 0.0197 - val_rmse: 0.0327\n","Epoch 26/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0523 - mae: 0.0385 - rmse: 0.0529 - val_loss: 0.0332 - val_mae: 0.0205 - val_rmse: 0.0332\n","Epoch 27/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0517 - mae: 0.0374 - rmse: 0.0509 - val_loss: 0.0332 - val_mae: 0.0201 - val_rmse: 0.0332\n","Epoch 28/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0538 - mae: 0.0395 - rmse: 0.0530 - val_loss: 0.0336 - val_mae: 0.0210 - val_rmse: 0.0336\n","Epoch 29/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0535 - mae: 0.0393 - rmse: 0.0540 - val_loss: 0.0327 - val_mae: 0.0196 - val_rmse: 0.0327\n","Epoch 30/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0516 - mae: 0.0380 - rmse: 0.0510 - val_loss: 0.0337 - val_mae: 0.0211 - val_rmse: 0.0337\n","Epoch 31/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0522 - mae: 0.0379 - rmse: 0.0524 - val_loss: 0.0327 - val_mae: 0.0197 - val_rmse: 0.0327\n","Epoch 32/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0512 - mae: 0.0377 - rmse: 0.0512 - val_loss: 0.0328 - val_mae: 0.0196 - val_rmse: 0.0328\n","Epoch 33/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0511 - mae: 0.0372 - rmse: 0.0503 - val_loss: 0.0326 - val_mae: 0.0196 - val_rmse: 0.0326\n","Epoch 34/50\n","37/37 [==============================] - 0s 8ms/step - loss: 0.0512 - mae: 0.0372 - rmse: 0.0515 - val_loss: 0.0328 - val_mae: 0.0199 - val_rmse: 0.0328\n","Epoch 35/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0498 - mae: 0.0365 - rmse: 0.0493 - val_loss: 0.0327 - val_mae: 0.0197 - val_rmse: 0.0327\n","Epoch 36/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0507 - mae: 0.0370 - rmse: 0.0504 - val_loss: 0.0330 - val_mae: 0.0203 - val_rmse: 0.0330\n","Epoch 37/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0482 - mae: 0.0353 - rmse: 0.0479 - val_loss: 0.0327 - val_mae: 0.0196 - val_rmse: 0.0327\n","Epoch 38/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0498 - mae: 0.0362 - rmse: 0.0495 - val_loss: 0.0330 - val_mae: 0.0203 - val_rmse: 0.0330\n","Epoch 39/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0492 - mae: 0.0357 - rmse: 0.0488 - val_loss: 0.0327 - val_mae: 0.0196 - val_rmse: 0.0327\n","Epoch 40/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0510 - mae: 0.0365 - rmse: 0.0508 - val_loss: 0.0332 - val_mae: 0.0206 - val_rmse: 0.0332\n","Epoch 41/50\n","37/37 [==============================] - 0s 9ms/step - loss: 0.0508 - mae: 0.0372 - rmse: 0.0507 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'model_json = model.to_json()\\nprint(model_json)\\nfilename = \\'models/lstm_\\' + time.strftime(\"%Y%m%d%H%M\") + \\'.h5\\'\\nmodel.save_weights(filename)'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"1c6J25PyODOA","executionInfo":{"status":"ok","timestamp":1626877722511,"user_tz":-60,"elapsed":352,"user":{"displayName":"Diogo Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gim-qZpf2wH4mvH2DAEkLs8Y3EiDCq8ol8sQcqySQ=s64","userId":"00234577802052720177"}},"outputId":"93f65016-6352-4d75-dcb6-600f6fa4359b"},"source":["def recursive_forecast(model, X_test, y_test, timesteps, multisteps, features, scaler, col_target_position, evaluation_timesteps=30):\n","    targer_scaler = scaler['value']    \n","    input_seq = X_test[-evaluation_timesteps:, :, :]\n","    labels_seq = y_test[-evaluation_timesteps:, :]\n","    results = list()\n","    for i in range(len(input_seq)-(multisteps-1)):  #we cannot go through the entire input because we are multistep forecasting!\n","        inp = input_seq[i].copy()\n","        lab = labels_seq[i].copy()\n","        #for each step of the multistep\n","        labels = list()\n","        predictions = list()\n","        for step in range(1, multisteps+1):\n","            #reshape\n","            inp = inp.reshape(1, timesteps, features)\n","            lab = lab.reshape(1, 1)\n","            #predict the value for the next timestep\n","            yhat = model.predict(inp, verbose=0)\n","            #invert normalized values\n","            lab_inversed = targer_scaler.inverse_transform(lab)\n","            yhat_inversed = targer_scaler.inverse_transform(yhat)\n","            #print(lab_inversed, yhat_inversed)\n","            #store results\n","            labels.append(lab_inversed[0][0])\n","            predictions.append(yhat_inversed[0][0])\n","            #insert a new value into the input sequence to predict the next timestep.\n","            if step != multisteps:\n","                #add yhat to the input sequence\n","                new_line = input_seq[i+step][-1].copy()\n","                np.put(new_line, col_target_position, yhat)\n","                new_line = new_line.reshape(1, features)\n","                inp = np.concatenate((inp[0], new_line))\n","                inp = inp[-timesteps:]\n","                #update label to the next timestep\n","                lab = labels_seq[i+step]\n","        results.append((np.array(predictions)))\n","    return np.array(results)\n","\n","#generated_data = np.random.uniform(low=6, high=9, size=9)\n","generated_data = [7.61, 7.075, 7.525, 6.9849, 7.105, 7.185, 7.04, 7.15, 7.165, 7.06]\n","generated_df = pd.DataFrame(generated_data, columns=['value'])\n","generated_df['value'] = scalers['value'].transform(generated_df[['value']])\n","X_generated, y_generated = tsp.to_supervised(generated_df , param_list[0][param_names.index('timesteps')])\n","generated_df['ph'] = scalers['value'].inverse_transform(generated_df[['value']])\n","display(generated_df)\n","print(recursive_forecast(model, X_generated, y_generated, param_list[0][param_names.index('timesteps')], 2, 1, scalers, generated_df.columns.get_loc('value')))"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>value</th>\n","      <th>ph</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.675541</td>\n","      <td>7.6100</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.586522</td>\n","      <td>7.0750</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.661398</td>\n","      <td>7.5250</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.571531</td>\n","      <td>6.9849</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.591514</td>\n","      <td>7.1050</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.604825</td>\n","      <td>7.1850</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.580699</td>\n","      <td>7.0400</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.599002</td>\n","      <td>7.1500</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.601498</td>\n","      <td>7.1650</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.584027</td>\n","      <td>7.0600</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      value      ph\n","0  0.675541  7.6100\n","1  0.586522  7.0750\n","2  0.661398  7.5250\n","3  0.571531  6.9849\n","4  0.591514  7.1050\n","5  0.604825  7.1850\n","6  0.580699  7.0400\n","7  0.599002  7.1500\n","8  0.601498  7.1650\n","9  0.584027  7.0600"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[[7.1515365 7.151877 ]\n"," [7.1513953 7.160382 ]]\n"],"name":"stdout"}]}]}