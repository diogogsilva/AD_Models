{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tests.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOoGtKmj53XgU00Tv6dYTIa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"062Ds2kL-2ta","outputId":"af6e0b31-9949-4a8f-bfc3-6f5bb87ef767"},"source":["'''\n","Mount Google Drive for COLAB\n","'''\n","\n","COLAB = True\n","\n","if COLAB:\n","  from google.colab import drive\n","  drive.mount('/content/gdrive', force_remount=True)\n","  %cd gdrive/My\\ Drive/Colab\\ Notebooks/Benchmark\n","  !pip install shap"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/Colab Notebooks/Benchmark\n","Collecting shap\n","  Downloading shap-0.39.0.tar.gz (356 kB)\n","\u001b[K     |████████████████████████████████| 356 kB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (0.22.2.post1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.41.1)\n","Collecting slicer==0.0.7\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.2.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.0.1)\n","Building wheels for collected packages: shap\n","  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491657 sha256=8b6ea49709879ab57775be24ea25806369ed99ec4480f19c1c6f207c9aeb2099\n","  Stored in directory: /root/.cache/pip/wheels/ca/25/8f/6ae5df62c32651cd719e972e738a8aaa4a87414c4d2b14c9c0\n","Successfully built shap\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"NpO4Vl6m_LDB","executionInfo":{"status":"ok","timestamp":1626787486432,"user_tz":-60,"elapsed":1478,"user":{"displayName":"Diogo Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gim-qZpf2wH4mvH2DAEkLs8Y3EiDCq8ol8sQcqySQ=s64","userId":"00234577802052720177"}},"outputId":"d9c6284c-29a9-4cf4-9ff7-7a5b816c50dc"},"source":["import pandas as pd\n","df = pd.read_csv(r'results/Experiments_lstm_model.csv', index_col=['experiment'])\n","df['mean_loss'] = (df['mae_blind'] + df['rmse_blind'] + df['loss'] + df['mae'] + df['rmse'])/5\n","display(df.sort_values(['mean_loss']))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>layers</th>\n","      <th>neurons</th>\n","      <th>dropout_rate</th>\n","      <th>activation</th>\n","      <th>timesteps</th>\n","      <th>batch_size</th>\n","      <th>epochs</th>\n","      <th>mae_blind</th>\n","      <th>rmse_blind</th>\n","      <th>loss</th>\n","      <th>mae</th>\n","      <th>rmse</th>\n","      <th>loss.1</th>\n","      <th>mae.1</th>\n","      <th>rmse.1</th>\n","      <th>train_time</th>\n","      <th>mean_loss</th>\n","    </tr>\n","    <tr>\n","      <th>experiment</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>relu</td>\n","      <td>7</td>\n","      <td>30</td>\n","      <td>25</td>\n","      <td>0.161644</td>\n","      <td>0.185609</td>\n","      <td>0.039410</td>\n","      <td>0.027029</td>\n","      <td>0.040088</td>\n","      <td>[[0.23685216]]</td>\n","      <td>[[0.16244385]]</td>\n","      <td>[[0.24092665]]</td>\n","      <td>20.758740</td>\n","      <td>0.090756</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>1</td>\n","      <td>128</td>\n","      <td>0.0</td>\n","      <td>relu</td>\n","      <td>14</td>\n","      <td>20</td>\n","      <td>25</td>\n","      <td>0.159393</td>\n","      <td>0.183446</td>\n","      <td>0.042684</td>\n","      <td>0.031192</td>\n","      <td>0.043333</td>\n","      <td>[[0.25653233]]</td>\n","      <td>[[0.18746299]]</td>\n","      <td>[[0.26043379]]</td>\n","      <td>24.218027</td>\n","      <td>0.092010</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>1</td>\n","      <td>32</td>\n","      <td>0.5</td>\n","      <td>tanh</td>\n","      <td>14</td>\n","      <td>20</td>\n","      <td>25</td>\n","      <td>0.164798</td>\n","      <td>0.189744</td>\n","      <td>0.039818</td>\n","      <td>0.027927</td>\n","      <td>0.040512</td>\n","      <td>[[0.23930526]]</td>\n","      <td>[[0.1678407]]</td>\n","      <td>[[0.24347428]]</td>\n","      <td>22.675887</td>\n","      <td>0.092560</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>tanh</td>\n","      <td>7</td>\n","      <td>20</td>\n","      <td>25</td>\n","      <td>0.167542</td>\n","      <td>0.191987</td>\n","      <td>0.039428</td>\n","      <td>0.027163</td>\n","      <td>0.040085</td>\n","      <td>[[0.23696198]]</td>\n","      <td>[[0.16324888]]</td>\n","      <td>[[0.24090847]]</td>\n","      <td>25.650270</td>\n","      <td>0.093241</td>\n","    </tr>\n","    <tr>\n","      <th>118</th>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>tanh</td>\n","      <td>7</td>\n","      <td>10</td>\n","      <td>25</td>\n","      <td>0.154548</td>\n","      <td>0.180119</td>\n","      <td>0.049114</td>\n","      <td>0.037328</td>\n","      <td>0.049475</td>\n","      <td>[[0.29517257]]</td>\n","      <td>[[0.22434057]]</td>\n","      <td>[[0.29734715]]</td>\n","      <td>52.318160</td>\n","      <td>0.094117</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>188</th>\n","      <td>2</td>\n","      <td>128</td>\n","      <td>0.0</td>\n","      <td>relu</td>\n","      <td>21</td>\n","      <td>20</td>\n","      <td>25</td>\n","      <td>0.254204</td>\n","      <td>0.279263</td>\n","      <td>0.051496</td>\n","      <td>0.038814</td>\n","      <td>0.051128</td>\n","      <td>[[0.30948997]]</td>\n","      <td>[[0.23327164]]</td>\n","      <td>[[0.30727759]]</td>\n","      <td>35.000761</td>\n","      <td>0.134981</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>1</td>\n","      <td>128</td>\n","      <td>0.0</td>\n","      <td>tanh</td>\n","      <td>14</td>\n","      <td>10</td>\n","      <td>25</td>\n","      <td>0.254173</td>\n","      <td>0.277859</td>\n","      <td>0.056254</td>\n","      <td>0.045654</td>\n","      <td>0.056603</td>\n","      <td>[[0.33808695]]</td>\n","      <td>[[0.27438171]]</td>\n","      <td>[[0.34018355]]</td>\n","      <td>36.904009</td>\n","      <td>0.138109</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>2</td>\n","      <td>64</td>\n","      <td>0.0</td>\n","      <td>relu</td>\n","      <td>21</td>\n","      <td>30</td>\n","      <td>25</td>\n","      <td>0.260263</td>\n","      <td>0.285597</td>\n","      <td>0.057760</td>\n","      <td>0.045044</td>\n","      <td>0.057353</td>\n","      <td>[[0.34713974]]</td>\n","      <td>[[0.270713]]</td>\n","      <td>[[0.34468896]]</td>\n","      <td>28.781191</td>\n","      <td>0.141203</td>\n","    </tr>\n","    <tr>\n","      <th>201</th>\n","      <td>2</td>\n","      <td>128</td>\n","      <td>0.5</td>\n","      <td>relu</td>\n","      <td>7</td>\n","      <td>30</td>\n","      <td>25</td>\n","      <td>0.270200</td>\n","      <td>0.291559</td>\n","      <td>0.053358</td>\n","      <td>0.041631</td>\n","      <td>0.053929</td>\n","      <td>[[0.32068426]]</td>\n","      <td>[[0.25020118]]</td>\n","      <td>[[0.32411312]]</td>\n","      <td>35.802069</td>\n","      <td>0.142135</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>2</td>\n","      <td>128</td>\n","      <td>0.0</td>\n","      <td>tanh</td>\n","      <td>7</td>\n","      <td>30</td>\n","      <td>25</td>\n","      <td>0.310796</td>\n","      <td>0.330536</td>\n","      <td>0.063629</td>\n","      <td>0.053879</td>\n","      <td>0.063790</td>\n","      <td>[[0.38240886]]</td>\n","      <td>[[0.32381003]]</td>\n","      <td>[[0.38337757]]</td>\n","      <td>31.375465</td>\n","      <td>0.164526</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>216 rows × 17 columns</p>\n","</div>"],"text/plain":["            layers  neurons  ...  train_time mean_loss\n","experiment                   ...                      \n","3                1       32  ...   20.758740  0.090756\n","77               1      128  ...   24.218027  0.092010\n","32               1       32  ...   22.675887  0.092560\n","11               1       32  ...   25.650270  0.093241\n","118              2       32  ...   52.318160  0.094117\n","...            ...      ...  ...         ...       ...\n","188              2      128  ...   35.000761  0.134981\n","85               1      128  ...   36.904009  0.138109\n","153              2       64  ...   28.781191  0.141203\n","201              2      128  ...   35.802069  0.142135\n","192              2      128  ...   31.375465  0.164526\n","\n","[216 rows x 17 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ptELzNpGCFKA","executionInfo":{"status":"ok","timestamp":1626787640607,"user_tz":-60,"elapsed":15840,"user":{"displayName":"Diogo Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gim-qZpf2wH4mvH2DAEkLs8Y3EiDCq8ol8sQcqySQ=s64","userId":"00234577802052720177"}},"outputId":"26c476f1-1f9a-44e9-d906-b48ebc827e3d"},"source":["SEED = 91195003\n","\n","import load_dataset as ld\n","import timeseries_preparation as tsp\n","import experiments as exp\n","import build_model as bm\n","import tensorflow as tf\n","from sklearn.model_selection import TimeSeriesSplit\n","import time\n","import numpy as np\n","\n","'''\n","Just load the dataset\n","'''\n","df_ph = ld.load_ph_dataset(univariate=True, colab=COLAB)\n","display(df_ph.sort_values(['value']))\n","\n","'''\n","Normalize it\n","'''\n","df_data = df_ph.copy()\n","scalers = tsp.data_normalization(df_data, norm_range=(0, 1))\n","\n","'''\n","Set the TimeSeries parameters\n","'''\n","multisteps = 2\n","cv_splits = 3\n","#must respect the name of the arguments of the build_model function\n","#timesteps are mandatory\n","hyperparameters = {\n","    'layers': [1],\n","    'neurons': [32],\n","    'dropout_rate': [0.0],\n","    'activation': ['relu'],\n","    'timesteps': [7],\n","    'batch_size': [30]\n","}\n","callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=25, min_lr=0.00005),\n","             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, mode='min', verbose=0, patience=40)]\n","\n","param_list, param_names = exp.prepare_param_list(hyperparameters, bm.build_lstm_model)\n","model = exp.build_model(1, param_names, param_list[0], bm.build_lstm_model, SEED)\n","print(model.summary())\n","\n","X, y = tsp.to_supervised(df_data, param_list[0][param_names.index('timesteps')])\n","tscv = TimeSeriesSplit(n_splits=cv_splits)\n","for train_index, test_index in tscv.split(X):\n","  train_idx, val_idx = tsp.split_dataset(train_index, perc=10)\n","  X_train, y_train = X[train_idx], y[train_idx] \n","  X_val, y_val = X[val_idx], y[val_idx] \n","  X_test, y_test = X[test_index], y[test_index]\n","  if callbacks:\n","    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=25, batch_size=param_list[0][param_names.index('batch_size')], shuffle=False, verbose=1, callbacks=callbacks)\n","'''model_json = model.to_json()\n","print(model_json)\n","filename = 'models/lstm_' + time.strftime(\"%Y%m%d%H%M\") + '.h5'\n","model.save_weights(filename)'''"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>value</th>\n","    </tr>\n","    <tr>\n","      <th>timestep</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2017-11-01</th>\n","      <td>3.550</td>\n","    </tr>\n","    <tr>\n","      <th>2016-05-20</th>\n","      <td>4.040</td>\n","    </tr>\n","    <tr>\n","      <th>2016-05-04</th>\n","      <td>4.160</td>\n","    </tr>\n","    <tr>\n","      <th>2017-11-15</th>\n","      <td>4.165</td>\n","    </tr>\n","    <tr>\n","      <th>2017-12-15</th>\n","      <td>4.200</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-25</th>\n","      <td>8.800</td>\n","    </tr>\n","    <tr>\n","      <th>2019-04-11</th>\n","      <td>9.020</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-24</th>\n","      <td>9.040</td>\n","    </tr>\n","    <tr>\n","      <th>2019-10-30</th>\n","      <td>9.200</td>\n","    </tr>\n","    <tr>\n","      <th>2019-08-13</th>\n","      <td>9.560</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1610 rows × 1 columns</p>\n","</div>"],"text/plain":["            value\n","timestep         \n","2017-11-01  3.550\n","2016-05-20  4.040\n","2016-05-04  4.160\n","2017-11-15  4.165\n","2017-12-15  4.200\n","...           ...\n","2019-11-25  8.800\n","2019-04-11  9.020\n","2019-11-24  9.040\n","2019-10-30  9.200\n","2019-08-13  9.560\n","\n","[1610 rows x 1 columns]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Model: \"lstm_model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, 7, 1)]            0         \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 16)                1152      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 32)                544       \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 33        \n","=================================================================\n","Total params: 1,729\n","Trainable params: 1,729\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/25\n","13/13 [==============================] - 2s 50ms/step - loss: 0.5351 - mae: 0.5328 - rmse: 0.5257 - val_loss: 0.4182 - val_mae: 0.4178 - val_rmse: 0.4102\n","Epoch 2/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.3288 - mae: 0.3273 - rmse: 0.3187 - val_loss: 0.1913 - val_mae: 0.1904 - val_rmse: 0.1846\n","Epoch 3/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0972 - mae: 0.0911 - rmse: 0.0972 - val_loss: 0.0775 - val_mae: 0.0752 - val_rmse: 0.0824\n","Epoch 4/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0553 - mae: 0.0448 - rmse: 0.0536 - val_loss: 0.0270 - val_mae: 0.0225 - val_rmse: 0.0238\n","Epoch 5/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0419 - mae: 0.0296 - rmse: 0.0426 - val_loss: 0.0267 - val_mae: 0.0233 - val_rmse: 0.0308\n","Epoch 6/25\n","13/13 [==============================] - 0s 6ms/step - loss: 0.0429 - mae: 0.0304 - rmse: 0.0427 - val_loss: 0.0213 - val_mae: 0.0174 - val_rmse: 0.0240\n","Epoch 7/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0403 - mae: 0.0273 - rmse: 0.0405 - val_loss: 0.0218 - val_mae: 0.0180 - val_rmse: 0.0247\n","Epoch 8/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0420 - mae: 0.0294 - rmse: 0.0420 - val_loss: 0.0223 - val_mae: 0.0187 - val_rmse: 0.0254\n","Epoch 9/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0408 - mae: 0.0279 - rmse: 0.0409 - val_loss: 0.0217 - val_mae: 0.0179 - val_rmse: 0.0245\n","Epoch 10/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0415 - mae: 0.0288 - rmse: 0.0416 - val_loss: 0.0223 - val_mae: 0.0187 - val_rmse: 0.0254\n","Epoch 11/25\n","13/13 [==============================] - 0s 6ms/step - loss: 0.0410 - mae: 0.0281 - rmse: 0.0411 - val_loss: 0.0219 - val_mae: 0.0182 - val_rmse: 0.0248\n","Epoch 12/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0412 - mae: 0.0285 - rmse: 0.0414 - val_loss: 0.0222 - val_mae: 0.0186 - val_rmse: 0.0252\n","Epoch 13/25\n","13/13 [==============================] - 0s 6ms/step - loss: 0.0410 - mae: 0.0282 - rmse: 0.0412 - val_loss: 0.0220 - val_mae: 0.0183 - val_rmse: 0.0249\n","Epoch 14/25\n","13/13 [==============================] - 0s 6ms/step - loss: 0.0410 - mae: 0.0282 - rmse: 0.0412 - val_loss: 0.0222 - val_mae: 0.0185 - val_rmse: 0.0251\n","Epoch 15/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0409 - mae: 0.0281 - rmse: 0.0411 - val_loss: 0.0221 - val_mae: 0.0184 - val_rmse: 0.0250\n","Epoch 16/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0409 - mae: 0.0281 - rmse: 0.0411 - val_loss: 0.0221 - val_mae: 0.0185 - val_rmse: 0.0251\n","Epoch 17/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0408 - mae: 0.0280 - rmse: 0.0410 - val_loss: 0.0221 - val_mae: 0.0185 - val_rmse: 0.0250\n","Epoch 18/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0408 - mae: 0.0279 - rmse: 0.0410 - val_loss: 0.0221 - val_mae: 0.0185 - val_rmse: 0.0250\n","Epoch 19/25\n","13/13 [==============================] - 0s 6ms/step - loss: 0.0407 - mae: 0.0278 - rmse: 0.0409 - val_loss: 0.0221 - val_mae: 0.0185 - val_rmse: 0.0250\n","Epoch 20/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0407 - mae: 0.0278 - rmse: 0.0408 - val_loss: 0.0221 - val_mae: 0.0185 - val_rmse: 0.0250\n","Epoch 21/25\n","13/13 [==============================] - 0s 6ms/step - loss: 0.0406 - mae: 0.0277 - rmse: 0.0408 - val_loss: 0.0221 - val_mae: 0.0185 - val_rmse: 0.0250\n","Epoch 22/25\n","13/13 [==============================] - 0s 8ms/step - loss: 0.0405 - mae: 0.0276 - rmse: 0.0407 - val_loss: 0.0221 - val_mae: 0.0185 - val_rmse: 0.0250\n","Epoch 23/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0405 - mae: 0.0275 - rmse: 0.0406 - val_loss: 0.0221 - val_mae: 0.0185 - val_rmse: 0.0249\n","Epoch 24/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0404 - mae: 0.0275 - rmse: 0.0406 - val_loss: 0.0221 - val_mae: 0.0185 - val_rmse: 0.0249\n","Epoch 25/25\n","13/13 [==============================] - 0s 7ms/step - loss: 0.0403 - mae: 0.0274 - rmse: 0.0405 - val_loss: 0.0221 - val_mae: 0.0185 - val_rmse: 0.0249\n","Epoch 1/25\n","25/25 [==============================] - 0s 7ms/step - loss: 0.0406 - mae: 0.0265 - rmse: 0.0404 - val_loss: 0.0421 - val_mae: 0.0325 - val_rmse: 0.0429\n","Epoch 2/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0405 - mae: 0.0265 - rmse: 0.0405 - val_loss: 0.0435 - val_mae: 0.0344 - val_rmse: 0.0444\n","Epoch 3/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0403 - mae: 0.0261 - rmse: 0.0402 - val_loss: 0.0433 - val_mae: 0.0342 - val_rmse: 0.0442\n","Epoch 4/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0403 - mae: 0.0261 - rmse: 0.0402 - val_loss: 0.0431 - val_mae: 0.0339 - val_rmse: 0.0439\n","Epoch 5/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0403 - mae: 0.0260 - rmse: 0.0401 - val_loss: 0.0429 - val_mae: 0.0338 - val_rmse: 0.0438\n","Epoch 6/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0402 - mae: 0.0259 - rmse: 0.0401 - val_loss: 0.0427 - val_mae: 0.0336 - val_rmse: 0.0437\n","Epoch 7/25\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0402 - mae: 0.0259 - rmse: 0.0400 - val_loss: 0.0426 - val_mae: 0.0334 - val_rmse: 0.0435\n","Epoch 8/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0401 - mae: 0.0258 - rmse: 0.0399 - val_loss: 0.0424 - val_mae: 0.0331 - val_rmse: 0.0433\n","Epoch 9/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0401 - mae: 0.0257 - rmse: 0.0399 - val_loss: 0.0421 - val_mae: 0.0329 - val_rmse: 0.0432\n","Epoch 10/25\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0400 - mae: 0.0257 - rmse: 0.0398 - val_loss: 0.0419 - val_mae: 0.0327 - val_rmse: 0.0430\n","Epoch 11/25\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0400 - mae: 0.0256 - rmse: 0.0398 - val_loss: 0.0417 - val_mae: 0.0324 - val_rmse: 0.0428\n","Epoch 12/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0399 - mae: 0.0255 - rmse: 0.0397 - val_loss: 0.0415 - val_mae: 0.0322 - val_rmse: 0.0426\n","Epoch 13/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0399 - mae: 0.0255 - rmse: 0.0396 - val_loss: 0.0413 - val_mae: 0.0319 - val_rmse: 0.0424\n","Epoch 14/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0399 - mae: 0.0254 - rmse: 0.0396 - val_loss: 0.0410 - val_mae: 0.0316 - val_rmse: 0.0421\n","Epoch 15/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0398 - mae: 0.0254 - rmse: 0.0395 - val_loss: 0.0408 - val_mae: 0.0313 - val_rmse: 0.0419\n","Epoch 16/25\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0398 - mae: 0.0253 - rmse: 0.0394 - val_loss: 0.0405 - val_mae: 0.0310 - val_rmse: 0.0417\n","Epoch 17/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0397 - mae: 0.0253 - rmse: 0.0394 - val_loss: 0.0403 - val_mae: 0.0307 - val_rmse: 0.0415\n","Epoch 18/25\n","25/25 [==============================] - 0s 7ms/step - loss: 0.0397 - mae: 0.0252 - rmse: 0.0393 - val_loss: 0.0400 - val_mae: 0.0304 - val_rmse: 0.0413\n","Epoch 19/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0397 - mae: 0.0252 - rmse: 0.0393 - val_loss: 0.0398 - val_mae: 0.0301 - val_rmse: 0.0410\n","Epoch 20/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.0251 - rmse: 0.0392 - val_loss: 0.0395 - val_mae: 0.0298 - val_rmse: 0.0408\n","Epoch 21/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.0251 - rmse: 0.0392 - val_loss: 0.0393 - val_mae: 0.0295 - val_rmse: 0.0406\n","Epoch 22/25\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0396 - mae: 0.0250 - rmse: 0.0391 - val_loss: 0.0390 - val_mae: 0.0292 - val_rmse: 0.0403\n","Epoch 23/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0395 - mae: 0.0250 - rmse: 0.0391 - val_loss: 0.0388 - val_mae: 0.0289 - val_rmse: 0.0401\n","Epoch 24/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0395 - mae: 0.0249 - rmse: 0.0390 - val_loss: 0.0385 - val_mae: 0.0285 - val_rmse: 0.0399\n","Epoch 25/25\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0395 - mae: 0.0249 - rmse: 0.0390 - val_loss: 0.0383 - val_mae: 0.0282 - val_rmse: 0.0396\n","Epoch 1/25\n","37/37 [==============================] - 1s 19ms/step - loss: 0.0369 - mae: 0.0246 - rmse: 0.0369 - val_loss: 0.0327 - val_mae: 0.0194 - val_rmse: 0.0327\n","Epoch 2/25\n","37/37 [==============================] - 0s 5ms/step - loss: 0.0371 - mae: 0.0250 - rmse: 0.0371 - val_loss: 0.0327 - val_mae: 0.0194 - val_rmse: 0.0327\n","Epoch 3/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0369 - mae: 0.0248 - rmse: 0.0370 - val_loss: 0.0327 - val_mae: 0.0194 - val_rmse: 0.0327\n","Epoch 4/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0369 - mae: 0.0248 - rmse: 0.0370 - val_loss: 0.0327 - val_mae: 0.0194 - val_rmse: 0.0327\n","Epoch 5/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0369 - mae: 0.0248 - rmse: 0.0369 - val_loss: 0.0327 - val_mae: 0.0194 - val_rmse: 0.0327\n","Epoch 6/25\n","37/37 [==============================] - 0s 5ms/step - loss: 0.0369 - mae: 0.0247 - rmse: 0.0369 - val_loss: 0.0327 - val_mae: 0.0194 - val_rmse: 0.0327\n","Epoch 7/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0368 - mae: 0.0247 - rmse: 0.0369 - val_loss: 0.0327 - val_mae: 0.0194 - val_rmse: 0.0327\n","Epoch 8/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0368 - mae: 0.0246 - rmse: 0.0369 - val_loss: 0.0327 - val_mae: 0.0194 - val_rmse: 0.0327\n","Epoch 9/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0368 - mae: 0.0246 - rmse: 0.0368 - val_loss: 0.0327 - val_mae: 0.0194 - val_rmse: 0.0327\n","Epoch 10/25\n","37/37 [==============================] - 1s 14ms/step - loss: 0.0368 - mae: 0.0246 - rmse: 0.0368 - val_loss: 0.0327 - val_mae: 0.0194 - val_rmse: 0.0327\n","Epoch 11/25\n","37/37 [==============================] - 0s 5ms/step - loss: 0.0367 - mae: 0.0246 - rmse: 0.0368 - val_loss: 0.0327 - val_mae: 0.0194 - val_rmse: 0.0327\n","Epoch 12/25\n","37/37 [==============================] - 0s 5ms/step - loss: 0.0367 - mae: 0.0245 - rmse: 0.0368 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n","Epoch 13/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0367 - mae: 0.0245 - rmse: 0.0368 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n","Epoch 14/25\n","37/37 [==============================] - 0s 5ms/step - loss: 0.0367 - mae: 0.0245 - rmse: 0.0367 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n","Epoch 15/25\n","37/37 [==============================] - 0s 5ms/step - loss: 0.0367 - mae: 0.0244 - rmse: 0.0367 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n","Epoch 16/25\n","37/37 [==============================] - 0s 5ms/step - loss: 0.0366 - mae: 0.0244 - rmse: 0.0367 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n","Epoch 17/25\n","37/37 [==============================] - 0s 5ms/step - loss: 0.0366 - mae: 0.0244 - rmse: 0.0367 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n","Epoch 18/25\n","37/37 [==============================] - 0s 5ms/step - loss: 0.0366 - mae: 0.0244 - rmse: 0.0367 - val_loss: 0.0328 - val_mae: 0.0195 - val_rmse: 0.0328\n","Epoch 19/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0366 - mae: 0.0244 - rmse: 0.0367 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n","Epoch 20/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0368 - mae: 0.0245 - rmse: 0.0369 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n","Epoch 21/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0370 - mae: 0.0248 - rmse: 0.0371 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n","Epoch 22/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0367 - mae: 0.0245 - rmse: 0.0368 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n","Epoch 23/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0367 - mae: 0.0245 - rmse: 0.0368 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n","Epoch 24/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0366 - mae: 0.0244 - rmse: 0.0367 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n","Epoch 25/25\n","37/37 [==============================] - 0s 6ms/step - loss: 0.0366 - mae: 0.0244 - rmse: 0.0367 - val_loss: 0.0327 - val_mae: 0.0195 - val_rmse: 0.0327\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'model_json = model.to_json()\\nprint(model_json)\\nfilename = \\'models/lstm_\\' + time.strftime(\"%Y%m%d%H%M\") + \\'.h5\\'\\nmodel.save_weights(filename)'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":657},"id":"1c6J25PyODOA","executionInfo":{"status":"ok","timestamp":1626788767723,"user_tz":-60,"elapsed":296,"user":{"displayName":"Diogo Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gim-qZpf2wH4mvH2DAEkLs8Y3EiDCq8ol8sQcqySQ=s64","userId":"00234577802052720177"}},"outputId":"ac356e4d-b3ef-4b64-a91a-4d2542add610"},"source":["def recursive_forecast(model, X_test, y_test, timesteps, multisteps, features, scaler, col_target_position, evaluation_timesteps=30):\n","    targer_scaler = scaler['value']    \n","    input_seq = X_test[-evaluation_timesteps:, :, :]\n","    labels_seq = y_test[-evaluation_timesteps:, :]\n","    results = list()\n","    for i in range(len(input_seq)-(multisteps-1)):  #we cannot go through the entire input because we are multistep forecasting!\n","        inp = input_seq[i].copy()\n","        print(inp)\n","        lab = labels_seq[i].copy()\n","        #for each step of the multistep\n","        labels = list()\n","        predictions = list()\n","        for step in range(1, multisteps+1):\n","            #reshape\n","            inp = inp.reshape(1, timesteps, features)\n","            lab = lab.reshape(1, 1)\n","            #predict the value for the next timestep\n","            yhat = model.predict(inp, verbose=0)\n","            #invert normalized values\n","            lab_inversed = targer_scaler.inverse_transform(lab)\n","            yhat_inversed = targer_scaler.inverse_transform(yhat)\n","            #print(lab_inversed, yhat_inversed)\n","            #store results\n","            labels.append(lab_inversed[0][0])\n","            predictions.append(yhat_inversed[0][0])\n","            #insert a new value into the input sequence to predict the next timestep.\n","            if step != multisteps:\n","                #add yhat to the input sequence\n","                new_line = input_seq[i+step][-1].copy()\n","                np.put(new_line, col_target_position, yhat)\n","                new_line = new_line.reshape(1, features)\n","                inp = np.concatenate((inp[0], new_line))\n","                inp = inp[-timesteps:]\n","                #update label to the next timestep\n","                lab = labels_seq[i+step]\n","        results.append((np.array(predictions)))\n","    return np.array(results)\n","\n","#generated_data = np.random.uniform(low=6, high=9, size=9)\n","generated_data = [7.61, 7.075, 7.525, 6.9849, 7.105, 7.185, 7.04, 7.15, 7.165, 7.06]\n","generated_df = pd.DataFrame(generated_data, columns=['value'])\n","generated_df['value'] = scalers['value'].transform(generated_df[['value']])\n","X_generated, y_generated = tsp.to_supervised(generated_df , param_list[0][param_names.index('timesteps')])\n","generated_df['ph'] = scalers['value'].inverse_transform(generated_df[['value']])\n","display(generated_df)\n","print(recursive_forecast(model, X_generated, y_generated, param_list[0][param_names.index('timesteps')], 2, 1, scalers, generated_df.columns.get_loc('value')))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>value</th>\n","      <th>ph</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.675541</td>\n","      <td>7.6100</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.586522</td>\n","      <td>7.0750</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.661398</td>\n","      <td>7.5250</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.571531</td>\n","      <td>6.9849</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.591514</td>\n","      <td>7.1050</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.604825</td>\n","      <td>7.1850</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.580699</td>\n","      <td>7.0400</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.599002</td>\n","      <td>7.1500</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.601498</td>\n","      <td>7.1650</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.584027</td>\n","      <td>7.0600</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      value      ph\n","0  0.675541  7.6100\n","1  0.586522  7.0750\n","2  0.661398  7.5250\n","3  0.571531  6.9849\n","4  0.591514  7.1050\n","5  0.604825  7.1850\n","6  0.580699  7.0400\n","7  0.599002  7.1500\n","8  0.601498  7.1650\n","9  0.584027  7.0600"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[[0.67554075]\n"," [0.58652246]\n"," [0.6613977 ]\n"," [0.57153076]\n"," [0.59151417]\n"," [0.6048253 ]\n"," [0.58069885]]\n","[[0.58652246]\n"," [0.6613977 ]\n"," [0.57153076]\n"," [0.59151417]\n"," [0.6048253 ]\n"," [0.58069885]\n"," [0.59900165]]\n","[[7.163911  7.143458 ]\n"," [7.140236  7.1433816]]\n"],"name":"stdout"}]}]}